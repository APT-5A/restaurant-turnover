{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNaTNkeOEDvSmSOkaYiooov"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Cell 1 — Mount Drive & set project paths**\n","\n","* Why: makes the notebook reproducible; every later cell uses these paths.\n","* Expect: a Drive prompt, then the path string.\n","* Watch-outs: if you see “Permission denied,” re-run the mount line.\n","\n","---\n","\n","\n"],"metadata":{"id":"w7vqJHU1Ka5G"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"7tI9iRN1KDAB","executionInfo":{"status":"ok","timestamp":1762967715314,"user_tz":300,"elapsed":18919,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"9017c658-82b4-4c83-bfdd-4139de786ade"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/restaurant-turnover'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["# Mount Google Drive so we can read/write files under /MyDrive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Point to your project root (update only if you used a different folder name)\n","PROJECT_ROOT = '/content/drive/MyDrive/restaurant-turnover'\n","\n","# Handy paths\n","from pathlib import Path\n","PR = Path(PROJECT_ROOT)\n","DATA_RAW  = PR/'data'/'raw'\n","DATA_PROC = PR/'data'/'processed'\n","OUT_MODELS = PR/'models'\n","OUT_SUBS   = PR/'outputs'/'submissions'\n","\n","for p in [DATA_RAW, DATA_PROC, OUT_MODELS, OUT_SUBS]:\n","    p.mkdir(parents=True, exist_ok=True)\n","\n","PROJECT_ROOT\n"]},{"cell_type":"markdown","source":["# **Cell 2 — Load train/test (CSV → Parquet cache)**\n","\n","* Why: Parquet loads faster and preserves dtypes.\n","* xpect: shapes like (3493, 34) and (500, 33).\n","* Watch-outs: if CSV not found, confirm your files are in data/raw."],"metadata":{"id":"v_D8hK6uKxUD"}},{"cell_type":"code","source":["import pandas as pd\n","\n","TRAIN_CSV = DATA_RAW/'Train_dataset_.csv'\n","TEST_CSV  = DATA_RAW/'Test_dataset_.csv'\n","TRAIN_PQ  = DATA_PROC/'train.parquet'\n","TEST_PQ   = DATA_PROC/'test.parquet'\n","\n","if TRAIN_PQ.exists() and TEST_PQ.exists():\n","    train = pd.read_parquet(TRAIN_PQ)\n","    test  = pd.read_parquet(TEST_PQ)\n","else:\n","    train = pd.read_csv(TRAIN_CSV)\n","    test  = pd.read_csv(TEST_CSV)\n","    train.to_parquet(TRAIN_PQ, index=False)\n","    test.to_parquet(TEST_PQ, index=False)\n","\n","train.shape, test.shape, list(train.columns)[:5]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sg3MaQQ7K6Tu","executionInfo":{"status":"ok","timestamp":1762967718022,"user_tz":300,"elapsed":2706,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"8cec6125-e31a-48bf-916b-4c826d90341d"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((3493, 34),\n"," (500, 33),\n"," ['Registration Number',\n","  'Annual Turnover',\n","  'Cuisine',\n","  'City',\n","  'Restaurant Location'])"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["# **Cell 3 — Schema guardrails (ID, target, uniqueness)**\n","\n","* Why: prevents accidental leakage or broken submissions later.\n","* Expect: “✅ Schema OK…”.\n","* Watch-outs: if an assert trips, stop—share the message."],"metadata":{"id":"f3-O4rgxK9w2"}},{"cell_type":"code","source":["ID_COL, TARGET = \"Registration Number\", \"Annual Turnover\"\n","\n","assert ID_COL in train.columns and ID_COL in test.columns, \"Missing ID column\"\n","assert TARGET in train.columns and TARGET not in test.columns, \"Target should be only in train\"\n","\n","assert train[ID_COL].is_unique, \"Duplicate IDs in train\"\n","assert test[ID_COL].is_unique,  \"Duplicate IDs in test\"\n","\n","print(\"✅ Schema OK. Rows:\", len(train), len(test))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"teMdFUlpLDqc","executionInfo":{"status":"ok","timestamp":1762967718029,"user_tz":300,"elapsed":7,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"869a0cfe-e78d-448b-9df4-614cfefb3c58"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Schema OK. Rows: 3493 500\n"]}]},{"cell_type":"markdown","source":["# **Cell 4 — Quick type inventory & basic missingness**\n","\n","* Why: guides imputation/encoding choices.\n","* Expect: the columns with most missing near the top.\n","* Watch-outs: none—just scanning."],"metadata":{"id":"z-eZfN4GL3N9"}},{"cell_type":"code","source":["num_cols_raw = train.select_dtypes(include='number').columns.tolist()\n","cat_cols_raw = train.select_dtypes(include=['object','category']).columns.tolist()\n","\n","print(\"Numeric:\", len(num_cols_raw), \"| Categorical:\", len(cat_cols_raw))\n","train.isna().mean().sort_values(ascending=False).head(10)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415},"id":"vOn9aoh1MAnb","executionInfo":{"status":"ok","timestamp":1762967718050,"user_tz":300,"elapsed":20,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"ce2483ab-9f08-4628-819a-0be5e904e908"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Numeric: 27 | Categorical: 7\n"]},{"output_type":"execute_result","data":{"text/plain":["Live Sports Rating               0.941311\n","Value Deals Rating               0.774979\n","Comedy Gigs Rating               0.710850\n","Live Music Rating                0.219009\n","Overall Restaurant Rating        0.060693\n","Facebook Popularity Quotient     0.028342\n","Instagram Popularity Quotient    0.016032\n","Resturant Tier                   0.014028\n","Ambience                         0.007157\n","Registration Number              0.000000\n","dtype: float64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Live Sports Rating</th>\n","      <td>0.941311</td>\n","    </tr>\n","    <tr>\n","      <th>Value Deals Rating</th>\n","      <td>0.774979</td>\n","    </tr>\n","    <tr>\n","      <th>Comedy Gigs Rating</th>\n","      <td>0.710850</td>\n","    </tr>\n","    <tr>\n","      <th>Live Music Rating</th>\n","      <td>0.219009</td>\n","    </tr>\n","    <tr>\n","      <th>Overall Restaurant Rating</th>\n","      <td>0.060693</td>\n","    </tr>\n","    <tr>\n","      <th>Facebook Popularity Quotient</th>\n","      <td>0.028342</td>\n","    </tr>\n","    <tr>\n","      <th>Instagram Popularity Quotient</th>\n","      <td>0.016032</td>\n","    </tr>\n","    <tr>\n","      <th>Resturant Tier</th>\n","      <td>0.014028</td>\n","    </tr>\n","    <tr>\n","      <th>Ambience</th>\n","      <td>0.007157</td>\n","    </tr>\n","    <tr>\n","      <th>Registration Number</th>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> float64</label>"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["# **Cell 5 — Branch clean copies (keep raw intact)**\n","\n","* Why: all cleanup happens on *_clean, preserving earlier EDA for reference.\n","* Expect: same shapes as raw.\n","* Watch-outs: none."],"metadata":{"id":"94FgV6nnME_s"}},{"cell_type":"code","source":["train_raw = train.copy()\n","test_raw  = test.copy()\n","\n","train_clean = train_raw.copy()\n","test_clean  = test_raw.copy()\n","\n","print(\"Branched. Clean shapes:\", train_clean.shape, test_clean.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LdMRCszYMObA","executionInfo":{"status":"ok","timestamp":1762967718063,"user_tz":300,"elapsed":12,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"348307fd-1737-4e79-f650-3913b3e76c2b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Branched. Clean shapes: (3493, 34) (500, 33)\n"]}]},{"cell_type":"markdown","source":["# **Cell 6 — Standardize column names (typos) & City sentinel**\n","\n","* Why: keeps train/test aligned; avoids a phantom category.\n","* Expect: “Unknown” appears in City counts if present.\n","* Watch-outs: typo might not exist—no problem."],"metadata":{"id":"MdX_Go2UMSwK"}},{"cell_type":"code","source":["# Fix known typo if present\n","rename_map = {\"Endoresed By\": \"Endorsed By\"}\n","train_clean.rename(columns=rename_map, inplace=True)\n","test_clean.rename(columns=rename_map, inplace=True)\n","\n","# Replace City sentinel \"-1\" with explicit category \"Unknown\"\n","if \"City\" in train_clean.columns:\n","    for df in (train_clean, test_clean):\n","        df[\"City\"] = df[\"City\"].replace({\"-1\": \"Unknown\"})\n","\n","print(\"Renames done. Example City values:\", train_clean.get(\"City\", pd.Series()).value_counts().head(5))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lQv34neaMhMo","executionInfo":{"status":"ok","timestamp":1762967718083,"user_tz":300,"elapsed":11,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"9e278a95-4cbb-4a72-c7da-a33aee182c40"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Renames done. Example City values: City\n","Bangalore    553\n","Unknown      396\n","Noida        324\n","Hyderabad    295\n","Pune         262\n","Name: count, dtype: int64\n"]}]},{"cell_type":"markdown","source":["# **Cell 7 — Parse dates (day-first) & make date features**\n","\n","* Why: models learn from age/seasonality, not raw date strings.\n","* Expect: reasonable stats (Age_days positive, month 1–12, dow 0–6).\n","* Watch-outs: if lots of NaT, earlier formats were odd; we already used dayfirst=True."],"metadata":{"id":"1vGf0j2KMk5s"}},{"cell_type":"code","source":["import pandas as pd\n","\n","DATE_COL = \"Opening Day of Restaurant\"\n","if DATE_COL in train_clean.columns:\n","    for df in (train_clean, test_clean):\n","        df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors=\"coerce\", dayfirst=True)\n","    anchor = pd.to_datetime(train_clean[DATE_COL]).max()\n","\n","    for df in (train_clean, test_clean):\n","        df[\"Age_days\"]   = (anchor - df[DATE_COL]).dt.days\n","        df[\"Open_month\"] = df[DATE_COL].dt.month\n","        df[\"Open_dow\"]   = df[DATE_COL].dt.dayofweek\n","\n","print(train_clean[[\"Age_days\",\"Open_month\",\"Open_dow\"]].describe().T)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"24HLiNJUMrwn","executionInfo":{"status":"ok","timestamp":1762967718144,"user_tz":300,"elapsed":57,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"83532212-a13e-4ec2-960d-ded5870f8320"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["             count         mean         std  min     25%     50%     75%  \\\n","Age_days    3493.0  2365.305754  640.424371  0.0  1904.0  2275.0  2752.0   \n","Open_month  3493.0     6.622960    3.357918  1.0     4.0     7.0     9.0   \n","Open_dow    3493.0     2.982823    2.004360  0.0     1.0     3.0     5.0   \n","\n","               max  \n","Age_days    7149.0  \n","Open_month    12.0  \n","Open_dow       6.0  \n"]}]},{"cell_type":"markdown","source":["# **Cell 8 — Ratings: missing flags + median impute**\n","\n","* Why: missing often means “feature absent” (useful signal); median is stable.\n","* Expect: non-zero count of flags.\n","* Watch-outs: none; median handles skew."],"metadata":{"id":"i6fPMKonMur2"}},{"cell_type":"code","source":["from sklearn.impute import SimpleImputer\n","rating_cols = [c for c in train_clean.columns if \"Rating\" in c and c != TARGET]\n","\n","# informative missingness flags\n","for c in rating_cols:\n","    train_clean[f\"{c}__isna\"] = train_clean[c].isna().astype(int)\n","    test_clean[f\"{c}__isna\"]  = test_clean[c].isna().astype(int)\n","\n","# robust numeric impute\n","if rating_cols:\n","    imp = SimpleImputer(strategy=\"median\")\n","    train_clean[rating_cols] = imp.fit_transform(train_clean[rating_cols])\n","    test_clean[rating_cols]  = imp.transform(test_clean[rating_cols])\n","\n","print(\"Added flags:\", len([c for c in train_clean.columns if c.endswith(\"__isna\")]))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vH-B20L0M0jP","executionInfo":{"status":"ok","timestamp":1762967719709,"user_tz":300,"elapsed":1564,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"1b351765-c3a1-400f-c4b1-80fa6849aca9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Added flags: 8\n"]}]},{"cell_type":"markdown","source":["# **Cell 9 — Categorical split by cardinality**\n","\n","* Why: one-hot small sets; encode large sets compactly.\n","* Expect: a handful of high-card (e.g., City, Theme).\n","* Watch-outs: if a numeric field was misread as object, we’ll catch it later."],"metadata":{"id":"-RB41GlyM-G_"}},{"cell_type":"code","source":["# Identify cats (post fixes)\n","cat_cols = train_clean.select_dtypes(include=['object','category']).columns.tolist()\n","cat_cols = [c for c in cat_cols if c not in [ID_COL, TARGET]]\n","\n","low_card  = [c for c in cat_cols if train_clean[c].nunique(dropna=True) <= 30]\n","high_card = [c for c in cat_cols if train_clean[c].nunique(dropna=True) > 30]\n","\n","print(\"Low-card:\", len(low_card), low_card[:8])\n","print(\"High-card:\", len(high_card), high_card[:8])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QQSfpTj0NE4Z","executionInfo":{"status":"ok","timestamp":1762967719710,"user_tz":300,"elapsed":5,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"fb3d26c6-256f-4a2e-a0a7-d045f94dd1f9"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Low-card: 4 ['Cuisine', 'Restaurant Location', 'Endorsed By', 'Restaurant Type']\n","High-card: 2 ['City', 'Restaurant Theme']\n"]}]},{"cell_type":"markdown","source":["# **Cell 10 — Build model matrices (one-hot low; frequency-encode high)**\n","\n","* Why: creates a numeric matrix for tree models; log1p(tgt) tames skew.\n","* Expect: same column count for train/test.\n","* Watch-outs: we’ll sanitize names next (LightGBM quirk)."],"metadata":{"id":"n05cbS9aNG3t"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# one-hot for low-card\n","train_oh = pd.get_dummies(train_clean[low_card], dummy_na=True) if low_card else pd.DataFrame(index=train_clean.index)\n","test_oh  = pd.get_dummies(test_clean[low_card],  dummy_na=True) if low_card else pd.DataFrame(index=test_clean.index)\n","if not (train_oh.empty and test_oh.empty):\n","    train_oh, test_oh = train_oh.align(test_oh, join=\"outer\", axis=1, fill_value=0)\n","\n","# frequency encoding for high-card\n","def freq_encode(s: pd.Series) -> pd.Series:\n","    freq = s.value_counts(normalize=True)\n","    return s.map(freq)\n","\n","for c in high_card:\n","    train_clean[c+\"_freq\"] = freq_encode(train_clean[c])\n","    test_clean[c+\"_freq\"]  = freq_encode(test_clean[c]).fillna(0)\n","\n","# numeric base (incl. date feats, ratings, flags), dropping ID/TARGET\n","num_cols = [c for c in train_clean.select_dtypes(include='number').columns if c not in [ID_COL, TARGET]]\n","\n","X_train = pd.concat([train_clean[num_cols], train_oh,\n","                     train_clean[[c+\"_freq\" for c in high_card]] if high_card else pd.DataFrame(index=train_clean.index)], axis=1)\n","X_test  = pd.concat([test_clean[[c for c in num_cols if c in test_clean.columns]], test_oh,\n","                     test_clean[[c+\"_freq\" for c in high_card if c+\"_freq\" in test_clean.columns]] if high_card else pd.DataFrame(index=test_clean.index)], axis=1)\n","\n","y_log = np.log1p(train_clean[TARGET]).reset_index(drop=True)\n","\n","X_train.shape, X_test.shape\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pZRfAr-QNN85","executionInfo":{"status":"ok","timestamp":1762967719727,"user_tz":300,"elapsed":17,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"eff7b228-e817-4a9c-ce16-32cabc4e1ee9"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((3493, 73), (500, 73))"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["# **Cell 11 — Sanitize column names & collapse duplicates**\n","\n","* Why: LightGBM rejects funky/duplicate names; we remove that risk.\n","* Expect: zero NaNs after fill; identical shapes.\n","* Watch-outs: if NaNs > 0, we’ll fill with medians—but usually 0 now."],"metadata":{"id":"4OU_znynNUf3"}},{"cell_type":"code","source":["import re\n","from collections import defaultdict\n","import pandas as pd\n","import numpy as np\n","\n","def sanitize_token(s: str) -> str:\n","    s = re.sub(r'[^0-9A-Za-z_]+', '_', str(s))\n","    s = re.sub(r'_+', '_', s).strip('_')\n","    return s or \"col\"\n","\n","def sanitize_columns(df: pd.DataFrame) -> pd.DataFrame:\n","    base = [sanitize_token(c) for c in df.columns]\n","    # de-dup names\n","    seen = {}; final = []\n","    for b in base:\n","        if b in seen:\n","            seen[b] += 1\n","            final.append(f\"{b}__{seen[b]}\")\n","        else:\n","            seen[b] = 0\n","            final.append(b)\n","    return df.set_axis(final, axis=1)\n","\n","def collapse_duplicate_columns(df: pd.DataFrame) -> pd.DataFrame:\n","    groups = defaultdict(list)\n","    for i, c in enumerate(df.columns): groups[c].append(i)\n","    new_df = pd.DataFrame(index=df.index)\n","    for name, idxs in groups.items():\n","        block = df.iloc[:, idxs]\n","        new_df[name] = block.iloc[:,0] if block.shape[1]==1 else block.mean(axis=1)\n","    return new_df\n","\n","X_train = collapse_duplicate_columns(sanitize_columns(X_train)).astype('float32')\n","X_test  = collapse_duplicate_columns(sanitize_columns(X_test)).astype('float32')\n","X_train, X_test = X_train.align(X_test, join='outer', axis=1, fill_value=0.0)\n","\n","print(\"✅ names sanitized. Shapes:\", X_train.shape, X_test.shape)\n","print(\"NaNs in X_train:\", int(X_train.isna().sum().sum()))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3FK2kxSaNa4v","executionInfo":{"status":"ok","timestamp":1762967719832,"user_tz":300,"elapsed":93,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"f9c89c9b-5f45-4cb2-f438-cfd60dc0ab0b"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ names sanitized. Shapes: (3493, 73) (500, 73)\n","NaNs in X_train: 229\n"]}]},{"cell_type":"markdown","source":["# **Cell 12 — Install LightGBM (once per runtime)**\n","\n","* Why: Colab sometimes lacks it by default.\n","* Expect: quiet install.\n","* Watch-outs: if you restart, re-run this."],"metadata":{"id":"HFCveL46Nd4t"}},{"cell_type":"code","source":["!pip -q install lightgbm\n"],"metadata":{"id":"Tj65Cv6SNkrR","executionInfo":{"status":"ok","timestamp":1762967723978,"user_tz":300,"elapsed":4141,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# **Cell 13 — Cross-validation (KFold) with early stopping**\n","\n","* Why: honest quality check vs the baseline (~21.5M).\n","* Expect: mean RMSE below baseline (likely ~20–21M with this simple setup).\n","\n","Watch-outs:\n","1. early_stopping_rounds not recognized → we’re using callbacks already (safe).\n","2. NaN error → go back to Cell 11 and ensure NaNs are 0; if not, fill with train medians."],"metadata":{"id":"BOQeowDONpic"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.model_selection import KFold\n","from lightgbm import LGBMRegressor, early_stopping, log_evaluation\n","\n","def rmse(y_true, y_pred):\n","    y_true = np.asarray(y_true); y_pred = np.asarray(y_pred)\n","    return float(np.sqrt(np.mean((y_true - y_pred)**2)))\n","\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","cv_scores, best_iters = [], []\n","\n","for tr, va in kf.split(X_train):\n","    model = LGBMRegressor(\n","        n_estimators=6000, learning_rate=0.02,\n","        num_leaves=31, min_child_samples=40,\n","        subsample=0.8, colsample_bytree=0.8,\n","        reg_lambda=1.0, random_state=42, n_jobs=-1\n","    )\n","    model.fit(\n","        X_train.iloc[tr], y_log.iloc[tr],\n","        eval_set=[(X_train.iloc[va], y_log.iloc[va])],\n","        eval_metric=\"rmse\",\n","        callbacks=[early_stopping(200), log_evaluation(100)]\n","    )\n","    best_iters.append(model.best_iteration_)\n","    pred_va = np.expm1(model.predict(X_train.iloc[va], num_iteration=model.best_iteration_))\n","    score = rmse(np.expm1(y_log.iloc[va]), pred_va)\n","    cv_scores.append(score)\n","    print(f\"Fold | best_iter={model.best_iteration_:>4} | RMSE: {score:,.0f}\")\n","\n","print(\"CV RMSE mean:\", f\"{np.mean(cv_scores):,.0f}\",\n","      \"| std:\", f\"{np.std(cv_scores):,.0f}\",\n","      \"| avg best_iter:\", int(np.mean(best_iters)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2EE7hpv_Oz3W","executionInfo":{"status":"ok","timestamp":1762967760807,"user_tz":300,"elapsed":36828,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"4a6dd356-6a16-4c73-cdfa-c782ff5e27c0"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003469 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1094\n","[LightGBM] [Info] Number of data points in the train set: 2794, number of used features: 59\n","[LightGBM] [Info] Start training from score 17.086072\n","Training until validation scores don't improve for 200 rounds\n","[100]\tvalid_0's rmse: 0.473522\tvalid_0's l2: 0.224223\n","[200]\tvalid_0's rmse: 0.464941\tvalid_0's l2: 0.21617\n","[300]\tvalid_0's rmse: 0.463465\tvalid_0's l2: 0.2148\n","[400]\tvalid_0's rmse: 0.463957\tvalid_0's l2: 0.215256\n","Early stopping, best iteration is:\n","[277]\tvalid_0's rmse: 0.463179\tvalid_0's l2: 0.214534\n","Fold | best_iter= 277 | RMSE: 19,296,476\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004999 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1094\n","[LightGBM] [Info] Number of data points in the train set: 2794, number of used features: 59\n","[LightGBM] [Info] Start training from score 17.080989\n","Training until validation scores don't improve for 200 rounds\n","[100]\tvalid_0's rmse: 0.478105\tvalid_0's l2: 0.228584\n","[200]\tvalid_0's rmse: 0.472832\tvalid_0's l2: 0.22357\n","[300]\tvalid_0's rmse: 0.47394\tvalid_0's l2: 0.224619\n","[400]\tvalid_0's rmse: 0.477399\tvalid_0's l2: 0.22791\n","Early stopping, best iteration is:\n","[253]\tvalid_0's rmse: 0.472582\tvalid_0's l2: 0.223333\n","Fold | best_iter= 253 | RMSE: 22,842,896\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007536 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1097\n","[LightGBM] [Info] Number of data points in the train set: 2794, number of used features: 59\n","[LightGBM] [Info] Start training from score 17.084947\n","Training until validation scores don't improve for 200 rounds\n","[100]\tvalid_0's rmse: 0.474487\tvalid_0's l2: 0.225138\n","[200]\tvalid_0's rmse: 0.466687\tvalid_0's l2: 0.217797\n","[300]\tvalid_0's rmse: 0.466614\tvalid_0's l2: 0.217729\n","[400]\tvalid_0's rmse: 0.468208\tvalid_0's l2: 0.219219\n","Early stopping, best iteration is:\n","[251]\tvalid_0's rmse: 0.465605\tvalid_0's l2: 0.216788\n","Fold | best_iter= 251 | RMSE: 20,728,440\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015880 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1092\n","[LightGBM] [Info] Number of data points in the train set: 2795, number of used features: 59\n","[LightGBM] [Info] Start training from score 17.093412\n","Training until validation scores don't improve for 200 rounds\n","[100]\tvalid_0's rmse: 0.464887\tvalid_0's l2: 0.21612\n","[200]\tvalid_0's rmse: 0.45708\tvalid_0's l2: 0.208922\n","[300]\tvalid_0's rmse: 0.458676\tvalid_0's l2: 0.210384\n","[400]\tvalid_0's rmse: 0.461022\tvalid_0's l2: 0.212542\n","Early stopping, best iteration is:\n","[216]\tvalid_0's rmse: 0.456836\tvalid_0's l2: 0.208699\n","Fold | best_iter= 216 | RMSE: 15,212,894\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084606 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1097\n","[LightGBM] [Info] Number of data points in the train set: 2795, number of used features: 59\n","[LightGBM] [Info] Start training from score 17.094060\n","Training until validation scores don't improve for 200 rounds\n","[100]\tvalid_0's rmse: 0.496182\tvalid_0's l2: 0.246197\n","[200]\tvalid_0's rmse: 0.488109\tvalid_0's l2: 0.23825\n","[300]\tvalid_0's rmse: 0.487402\tvalid_0's l2: 0.237561\n","[400]\tvalid_0's rmse: 0.488996\tvalid_0's l2: 0.239118\n","Early stopping, best iteration is:\n","[264]\tvalid_0's rmse: 0.486817\tvalid_0's l2: 0.236991\n","Fold | best_iter= 264 | RMSE: 22,311,673\n","CV RMSE mean: 20,078,476 | std: 2,732,656 | avg best_iter: 252\n"]}]},{"cell_type":"markdown","source":["# **Cell 14 — Train final model & predict test**\n","\n","* Why: fit once on all data using a sensible tree count.\n","* Expect: length 500; values similar order of magnitude as the target.\n","* Watch-outs: if wildly tiny/huge, we investigate features."],"metadata":{"id":"kKLt4PE7O5Oe"}},{"cell_type":"code","source":["from lightgbm import LGBMRegressor\n","best_iter = int(np.mean(best_iters)) if best_iters else 1200\n","\n","final = LGBMRegressor(\n","    n_estimators=best_iter, learning_rate=0.02,\n","    num_leaves=31, min_child_samples=40,\n","    subsample=0.8, colsample_bytree=0.8,\n","    reg_lambda=1.0, random_state=42, n_jobs=-1\n",").fit(X_train, y_log)\n","\n","test_pred = np.expm1(final.predict(X_test))\n","len(test_pred), test_pred[:5]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rks5ST3mO_5S","executionInfo":{"status":"ok","timestamp":1762967761311,"user_tz":300,"elapsed":492,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"182437c2-09af-4621-edeb-bba9d82e8a1b"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001083 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1106\n","[LightGBM] [Info] Number of data points in the train set: 3493, number of used features: 63\n","[LightGBM] [Info] Start training from score 17.087897\n"]},{"output_type":"execute_result","data":{"text/plain":["(500,\n"," array([23290084.44039058, 30517262.75302121, 26460906.41322152,\n","        41224087.10638832, 41213043.40954559]))"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["# **Cell 15 — Build & save submission (format-checked)**\n","\n","* Why: exact required two columns; 500 rows.\n","* Expect: a CSV path printed.\n","* Watch-outs: assertion messages are your friend if something’s off."],"metadata":{"id":"WQXQVQtOPEt8"}},{"cell_type":"code","source":["import pandas as pd\n","from pathlib import Path\n","\n","sub = test_clean[[ID_COL]].copy()\n","sub[\"Annual Turnover\"] = test_pred\n","\n","# Save (overwrite okay while iterating)\n","OUT_SUBS.mkdir(parents=True, exist_ok=True)\n","out_path = OUT_SUBS/\"submission_lgbm_step1.csv\"\n","sub.to_csv(out_path, index=False)\n","\n","# Hard checks per hackathon spec\n","assert sub.columns.tolist() == [\"Registration Number\",\"Annual Turnover\"]\n","assert len(sub) == 500\n","assert sub[ID_COL].is_unique\n","\n","print(\"✅ Submission saved:\", out_path)\n","sub.head()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"kY-vVJ8NPOcw","executionInfo":{"status":"ok","timestamp":1762967761843,"user_tz":300,"elapsed":530,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"4f0317e5-d70c-4e8d-d6bf-07f29211094a"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Submission saved: /content/drive/MyDrive/restaurant-turnover/outputs/submissions/submission_lgbm_step1.csv\n"]},{"output_type":"execute_result","data":{"text/plain":["   Registration Number  Annual Turnover\n","0                20001     2.329008e+07\n","1                20002     3.051726e+07\n","2                20003     2.646091e+07\n","3                20004     4.122409e+07\n","4                20005     4.121304e+07"],"text/html":["\n","  <div id=\"df-009d3ab2-9bc0-491b-a8c2-1cd1e461bb5b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Registration Number</th>\n","      <th>Annual Turnover</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>20001</td>\n","      <td>2.329008e+07</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20002</td>\n","      <td>3.051726e+07</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>20003</td>\n","      <td>2.646091e+07</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>20004</td>\n","      <td>4.122409e+07</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>20005</td>\n","      <td>4.121304e+07</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-009d3ab2-9bc0-491b-a8c2-1cd1e461bb5b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-009d3ab2-9bc0-491b-a8c2-1cd1e461bb5b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-009d3ab2-9bc0-491b-a8c2-1cd1e461bb5b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-133e8cfd-7109-4a6e-9b98-8d8887bd8257\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-133e8cfd-7109-4a6e-9b98-8d8887bd8257')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-133e8cfd-7109-4a6e-9b98-8d8887bd8257 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"sub","summary":"{\n  \"name\": \"sub\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"Registration Number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 144,\n        \"min\": 20001,\n        \"max\": 20500,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          20362,\n          20074,\n          20375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Annual Turnover\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7735725.502304614,\n        \"min\": 12672072.689202953,\n        \"max\": 54797863.94009012,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          21958564.30971734,\n          22669569.995273113,\n          24637562.84966541\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["# **Cell 16 — Feature importance (sanity check)**\n","\n","* Why: confirm the model leans on sensible signals (age, tiers, ratings, party-hub, city/theme encodings).\n","* Watch for: anything ID-ish near the top (bad); all zeros (means something went wrong earlier)."],"metadata":{"id":"allO69WQP21T"}},{"cell_type":"code","source":["import pandas as pd\n","\n","imp = pd.Series(final.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n","top20 = imp.head(20).to_frame(\"gain\")\n","display(top20)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":677},"id":"DtgfLBK1P9TV","executionInfo":{"status":"ok","timestamp":1762967761867,"user_tz":300,"elapsed":23,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"781cf32c-a77f-4c83-e1c4-b3f0e0819710"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":["                               gain\n","Age_days                        880\n","Instagram_Popularity_Quotient   672\n","Facebook_Popularity_Quotient    671\n","City_freq                       586\n","Open_month                      252\n","Ambience                        237\n","Comfortablility                 235\n","Order_Wait_Time                 220\n","Hygiene_Rating                  220\n","Live_Music_Rating               219\n","Service                         210\n","Restaurant_Zomato_Rating        206\n","Privacy                         195\n","Lively                          194\n","Staff_Responsivness             188\n","Open_dow                        187\n","Restaurant_Theme_freq           187\n","Overall_Restaurant_Rating       167\n","Cuisine_tibetan_greek           139\n","City_freq__1                    131"],"text/html":["\n","  <div id=\"df-7f8e2eea-6a73-457f-9bfe-05da16440f3f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>gain</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Age_days</th>\n","      <td>880</td>\n","    </tr>\n","    <tr>\n","      <th>Instagram_Popularity_Quotient</th>\n","      <td>672</td>\n","    </tr>\n","    <tr>\n","      <th>Facebook_Popularity_Quotient</th>\n","      <td>671</td>\n","    </tr>\n","    <tr>\n","      <th>City_freq</th>\n","      <td>586</td>\n","    </tr>\n","    <tr>\n","      <th>Open_month</th>\n","      <td>252</td>\n","    </tr>\n","    <tr>\n","      <th>Ambience</th>\n","      <td>237</td>\n","    </tr>\n","    <tr>\n","      <th>Comfortablility</th>\n","      <td>235</td>\n","    </tr>\n","    <tr>\n","      <th>Order_Wait_Time</th>\n","      <td>220</td>\n","    </tr>\n","    <tr>\n","      <th>Hygiene_Rating</th>\n","      <td>220</td>\n","    </tr>\n","    <tr>\n","      <th>Live_Music_Rating</th>\n","      <td>219</td>\n","    </tr>\n","    <tr>\n","      <th>Service</th>\n","      <td>210</td>\n","    </tr>\n","    <tr>\n","      <th>Restaurant_Zomato_Rating</th>\n","      <td>206</td>\n","    </tr>\n","    <tr>\n","      <th>Privacy</th>\n","      <td>195</td>\n","    </tr>\n","    <tr>\n","      <th>Lively</th>\n","      <td>194</td>\n","    </tr>\n","    <tr>\n","      <th>Staff_Responsivness</th>\n","      <td>188</td>\n","    </tr>\n","    <tr>\n","      <th>Open_dow</th>\n","      <td>187</td>\n","    </tr>\n","    <tr>\n","      <th>Restaurant_Theme_freq</th>\n","      <td>187</td>\n","    </tr>\n","    <tr>\n","      <th>Overall_Restaurant_Rating</th>\n","      <td>167</td>\n","    </tr>\n","    <tr>\n","      <th>Cuisine_tibetan_greek</th>\n","      <td>139</td>\n","    </tr>\n","    <tr>\n","      <th>City_freq__1</th>\n","      <td>131</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f8e2eea-6a73-457f-9bfe-05da16440f3f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7f8e2eea-6a73-457f-9bfe-05da16440f3f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7f8e2eea-6a73-457f-9bfe-05da16440f3f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-2b4ba202-67c9-445e-a02e-40958882e776\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2b4ba202-67c9-445e-a02e-40958882e776')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-2b4ba202-67c9-445e-a02e-40958882e776 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_61792617-d424-4d80-a221-2565f552d5da\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('top20')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_61792617-d424-4d80-a221-2565f552d5da button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('top20');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"top20","summary":"{\n  \"name\": \"top20\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"gain\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          880,\n          672,\n          219\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"markdown","source":["# **Cell 17 — Scale sanity: target vs predictions**\n","\n","* Why: quick visual check that predictions live in the right ballpark.\n","* Watch for: predictions all crammed into a tiny range or orders of magnitude off."],"metadata":{"id":"SI9Y8P_3QC60"}},{"cell_type":"code","source":["import numpy as np, matplotlib.pyplot as plt\n","\n","print(\"Train target summary:\")\n","display(train_clean[\"Annual Turnover\"].describe(percentiles=[.01,.05,.5,.95,.99]))\n","\n","print(\"Test prediction summary:\")\n","display(pd.Series(test_pred, name=\"Annual Turnover\").describe(percentiles=[.01,.05,.5,.95,.99]))\n","\n","plt.figure(figsize=(10,4))\n","plt.hist(train_clean[\"Annual Turnover\"], bins=40, alpha=0.5, label=\"train target\")\n","plt.hist(test_pred, bins=40, alpha=0.5, label=\"test preds\")\n","plt.title(\"Scale check\"); plt.legend(); plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"CHiwpD17QInR","executionInfo":{"status":"ok","timestamp":1762967762318,"user_tz":300,"elapsed":450,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"581edec0-6589-4ea5-f698-0f8319e625f8"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Train target summary:\n"]},{"output_type":"display_data","data":{"text/plain":["count    3.493000e+03\n","mean     3.072571e+07\n","std      2.165125e+07\n","min      3.500000e+06\n","1%       7.000000e+06\n","5%       1.000000e+07\n","50%      3.000000e+07\n","95%      5.700000e+07\n","99%      1.000000e+08\n","max      4.000000e+08\n","Name: Annual Turnover, dtype: float64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Annual Turnover</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>3.493000e+03</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>3.072571e+07</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>2.165125e+07</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>3.500000e+06</td>\n","    </tr>\n","    <tr>\n","      <th>1%</th>\n","      <td>7.000000e+06</td>\n","    </tr>\n","    <tr>\n","      <th>5%</th>\n","      <td>1.000000e+07</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>3.000000e+07</td>\n","    </tr>\n","    <tr>\n","      <th>95%</th>\n","      <td>5.700000e+07</td>\n","    </tr>\n","    <tr>\n","      <th>99%</th>\n","      <td>1.000000e+08</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>4.000000e+08</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> float64</label>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Test prediction summary:\n"]},{"output_type":"display_data","data":{"text/plain":["count    5.000000e+02\n","mean     2.706277e+07\n","std      7.735726e+06\n","min      1.267207e+07\n","1%       1.352031e+07\n","5%       1.620183e+07\n","50%      2.598830e+07\n","95%      4.067734e+07\n","99%      4.780490e+07\n","max      5.479786e+07\n","Name: Annual Turnover, dtype: float64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Annual Turnover</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>5.000000e+02</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>2.706277e+07</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>7.735726e+06</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.267207e+07</td>\n","    </tr>\n","    <tr>\n","      <th>1%</th>\n","      <td>1.352031e+07</td>\n","    </tr>\n","    <tr>\n","      <th>5%</th>\n","      <td>1.620183e+07</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>2.598830e+07</td>\n","    </tr>\n","    <tr>\n","      <th>95%</th>\n","      <td>4.067734e+07</td>\n","    </tr>\n","    <tr>\n","      <th>99%</th>\n","      <td>4.780490e+07</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>5.479786e+07</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> float64</label>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x400 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["# **Cell 18 — K-Fold target encoding for City + rebuild matrices + CV**\n","\n","* Why: City is high-card and drift-prone. CV-safe target encoding often adds signal beyond frequency counts.\n","* Expect: CV mean a bit below your plain LGBM baseline (ideally closer to your CatBoost ~19.8M).\n","\n","Watch-outs:\n","* If you see ValueError: ... not found, double-check column name spelling.\n","* If NaN errors appear, ensure Cell 11 (sanitize/collapse) was run earlier in this fresh notebook too."],"metadata":{"id":"LNdWAXgsQgGM"}},{"cell_type":"code","source":["# --- KFold target encoding for 'City' (leak-safe) ---\n","from sklearn.model_selection import KFold\n","import pandas as pd\n","import numpy as np\n","\n","TARGET = \"Annual Turnover\"\n","ID_COL = \"Registration Number\"\n","\n","def kfold_target_encode(train_df, test_df, col, target, n_splits=5, smoothing=200, seed=42):\n","    \"\"\"Create col__te using KFold means with smoothing (no leakage).\"\"\"\n","    tr = train_df[[col, target]].copy()\n","    global_mean = tr[target].mean()\n","\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    oof = pd.Series(index=train_df.index, dtype=float)\n","\n","    for tr_idx, va_idx in kf.split(tr):\n","        tr_fold = tr.iloc[tr_idx]\n","        stats = tr_fold.groupby(col)[target].agg(['mean','count'])\n","        stats['te'] = (stats['count']*stats['mean'] + smoothing*global_mean) / (stats['count'] + smoothing)\n","        oof.iloc[va_idx] = tr.iloc[va_idx][col].map(stats['te']).fillna(global_mean)\n","\n","    stats = tr.groupby(col)[target].agg(['mean','count'])\n","    stats['te'] = (stats['count']*stats['mean'] + smoothing*global_mean) / (stats['count'] + smoothing)\n","    test_te = test_df[col].map(stats['te']).fillna(global_mean)\n","\n","    train_df[f\"{col}__te\"] = oof.values\n","    test_df[f\"{col}__te\"]  = test_te.values\n","    return train_df, test_df\n","\n","# 1) Make TE copies and encode City\n","train_te = train_clean.copy()\n","test_te  = test_clean.copy()\n","if \"City\" in train_te.columns:\n","    train_te, test_te = kfold_target_encode(train_te, test_te, \"City\", TARGET, n_splits=5, smoothing=200)\n","else:\n","    raise ValueError(\"Column 'City' not found for target encoding.\")\n","\n","# 2) Build matrices: numerics (+ new City__te), one-hot low-card categoricals\n","cat_cols = train_te.select_dtypes(include=['object','category']).columns.tolist()\n","cat_cols = [c for c in cat_cols if c not in [ID_COL, TARGET]]\n","\n","low_card  = [c for c in cat_cols if train_te[c].nunique(dropna=True) <= 30]\n","\n","train_oh = pd.get_dummies(train_te[low_card], dummy_na=True) if low_card else pd.DataFrame(index=train_te.index)\n","test_oh  = pd.get_dummies(test_te[low_card],  dummy_na=True) if low_card else pd.DataFrame(index=test_te.index)\n","if not (train_oh.empty and test_oh.empty):\n","    train_oh, test_oh = train_oh.align(test_oh, join=\"outer\", axis=1, fill_value=0)\n","\n","num_cols = [c for c in train_te.select_dtypes(include='number').columns if c not in [ID_COL, TARGET]]\n","\n","X_city = pd.concat([train_te[num_cols], train_oh, train_te[[\"City__te\"]]], axis=1)\n","T_city = pd.concat([test_te[[c for c in num_cols if c in test_te.columns]], test_oh, test_te[[\"City__te\"]]], axis=1)\n","\n","# 3) Sanitize names + collapse duplicates (functions defined earlier in Cell 11)\n","X_city  = collapse_duplicate_columns(sanitize_columns(X_city)).astype(\"float32\")\n","T_city  = collapse_duplicate_columns(sanitize_columns(T_city)).astype(\"float32\")\n","X_city, T_city = X_city.align(T_city, join=\"outer\", axis=1, fill_value=0.0)\n","\n","# 4) CV with LightGBM on log target\n","from sklearn.model_selection import KFold\n","from lightgbm import LGBMRegressor, early_stopping, log_evaluation\n","\n","y_log_city = np.log1p(train_te[TARGET]).reset_index(drop=True)\n","\n","def rmse(y_true, y_pred):\n","    y_true = np.asarray(y_true); y_pred = np.asarray(y_pred)\n","    return float(np.sqrt(np.mean((y_true - y_pred)**2)))\n","\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","cv_scores, best_iters = [], []\n","\n","for tr, va in kf.split(X_city):\n","    model = LGBMRegressor(\n","        n_estimators=6000, learning_rate=0.02,\n","        num_leaves=31, min_child_samples=40,\n","        subsample=0.8, colsample_bytree=0.8,\n","        reg_lambda=1.0, random_state=42, n_jobs=-1\n","    )\n","    model.fit(\n","        X_city.iloc[tr], y_log_city.iloc[tr],\n","        eval_set=[(X_city.iloc[va], y_log_city.iloc[va])],\n","        eval_metric=\"rmse\",\n","        callbacks=[early_stopping(200), log_evaluation(100)]\n","    )\n","    pred = np.expm1(model.predict(X_city.iloc[va], num_iteration=model.best_iteration_))\n","    score = rmse(np.expm1(y_log_city.iloc[va]), pred)\n","    cv_scores.append(score); best_iters.append(model.best_iteration_)\n","    print(f\"Fold | best_iter={model.best_iteration_:>4} | RMSE: {score:,.0f}\")\n","\n","print(\"LGBM + City__te | CV mean:\", f\"{np.mean(cv_scores):,.0f}\",\n","      \"| std:\", f\"{np.std(cv_scores):,.0f}\",\n","      \"| avg best_iter:\", int(np.mean(best_iters)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OnY0Ye9CQ32i","executionInfo":{"status":"ok","timestamp":1762967787557,"user_tz":300,"elapsed":25238,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"86917ae3-5438-47b9-8e5c-42867ebe5195"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038805 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1358\n","[LightGBM] [Info] Number of data points in the train set: 2794, number of used features: 59\n","[LightGBM] [Info] Start training from score 17.086072\n","Training until validation scores don't improve for 200 rounds\n","[100]\tvalid_0's rmse: 0.47017\tvalid_0's l2: 0.22106\n","[200]\tvalid_0's rmse: 0.461495\tvalid_0's l2: 0.212977\n","[300]\tvalid_0's rmse: 0.460546\tvalid_0's l2: 0.212102\n","[400]\tvalid_0's rmse: 0.461148\tvalid_0's l2: 0.212658\n","Early stopping, best iteration is:\n","[273]\tvalid_0's rmse: 0.460247\tvalid_0's l2: 0.211827\n","Fold | best_iter= 273 | RMSE: 19,324,831\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076567 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1354\n","[LightGBM] [Info] Number of data points in the train set: 2794, number of used features: 59\n","[LightGBM] [Info] Start training from score 17.080989\n","Training until validation scores don't improve for 200 rounds\n","[100]\tvalid_0's rmse: 0.477589\tvalid_0's l2: 0.228092\n","[200]\tvalid_0's rmse: 0.47316\tvalid_0's l2: 0.22388\n","[300]\tvalid_0's rmse: 0.474705\tvalid_0's l2: 0.225345\n","[400]\tvalid_0's rmse: 0.476291\tvalid_0's l2: 0.226853\n","Early stopping, best iteration is:\n","[200]\tvalid_0's rmse: 0.47316\tvalid_0's l2: 0.22388\n","Fold | best_iter= 200 | RMSE: 22,915,899\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125687 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1361\n","[LightGBM] [Info] Number of data points in the train set: 2794, number of used features: 59\n","[LightGBM] [Info] Start training from score 17.084947\n","Training until validation scores don't improve for 200 rounds\n","[100]\tvalid_0's rmse: 0.470976\tvalid_0's l2: 0.221819\n","[200]\tvalid_0's rmse: 0.463222\tvalid_0's l2: 0.214574\n","[300]\tvalid_0's rmse: 0.465384\tvalid_0's l2: 0.216583\n","[400]\tvalid_0's rmse: 0.469291\tvalid_0's l2: 0.220234\n","Early stopping, best iteration is:\n","[217]\tvalid_0's rmse: 0.46236\tvalid_0's l2: 0.213777\n","Fold | best_iter= 217 | RMSE: 20,672,612\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.130964 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1354\n","[LightGBM] [Info] Number of data points in the train set: 2795, number of used features: 59\n","[LightGBM] [Info] Start training from score 17.093412\n","Training until validation scores don't improve for 200 rounds\n","[100]\tvalid_0's rmse: 0.461013\tvalid_0's l2: 0.212533\n","[200]\tvalid_0's rmse: 0.453902\tvalid_0's l2: 0.206027\n","[300]\tvalid_0's rmse: 0.455069\tvalid_0's l2: 0.207088\n","[400]\tvalid_0's rmse: 0.457407\tvalid_0's l2: 0.209221\n","Early stopping, best iteration is:\n","[261]\tvalid_0's rmse: 0.453692\tvalid_0's l2: 0.205837\n","Fold | best_iter= 261 | RMSE: 15,150,620\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078574 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1359\n","[LightGBM] [Info] Number of data points in the train set: 2795, number of used features: 59\n","[LightGBM] [Info] Start training from score 17.094060\n","Training until validation scores don't improve for 200 rounds\n","[100]\tvalid_0's rmse: 0.488088\tvalid_0's l2: 0.238229\n","[200]\tvalid_0's rmse: 0.480829\tvalid_0's l2: 0.231197\n","[300]\tvalid_0's rmse: 0.481934\tvalid_0's l2: 0.23226\n","Early stopping, best iteration is:\n","[190]\tvalid_0's rmse: 0.480387\tvalid_0's l2: 0.230772\n","Fold | best_iter= 190 | RMSE: 22,264,619\n","LGBM + City__te | CV mean: 20,065,716 | std: 2,758,047 | avg best_iter: 228\n"]}]},{"cell_type":"markdown","source":["# **Cell 19 — Train final on City-TE matrix + write a new submission**\n","\n","* Why: produce a submission from the improved feature set.\n","* Expect: file saved under outputs/submissions/.\n","* Watch-outs: column order/row count assertions guard the required format."],"metadata":{"id":"ynZ6jHXCROil"}},{"cell_type":"code","source":["from lightgbm import LGBMRegressor\n","from pathlib import Path\n","import pandas as pd\n","best_iter = int(np.mean(best_iters)) if best_iters else 1200\n","\n","final_city = LGBMRegressor(\n","    n_estimators=best_iter, learning_rate=0.02,\n","    num_leaves=31, min_child_samples=40,\n","    subsample=0.8, colsample_bytree=0.8,\n","    reg_lambda=1.0, random_state=42, n_jobs=-1\n",").fit(X_city, y_log_city)\n","\n","test_pred_city = np.expm1(final_city.predict(T_city))\n","\n","sub_city = test_clean[[\"Registration Number\"]].copy()\n","sub_city[\"Annual Turnover\"] = test_pred_city\n","\n","out_path = OUT_SUBS/\"submission_lgbm_cityTE.csv\"\n","sub_city.to_csv(out_path, index=False)\n","\n","# required checks\n","assert sub_city.columns.tolist() == [\"Registration Number\",\"Annual Turnover\"]\n","assert len(sub_city) == 500 and sub_city[\"Registration Number\"].is_unique\n","print(\"✅ Saved:\", out_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qld2cQPVRUd9","executionInfo":{"status":"ok","timestamp":1762967790123,"user_tz":300,"elapsed":2541,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"40b0d401-df11-4d49-80f0-ed3654ee9cc7"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004988 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1512\n","[LightGBM] [Info] Number of data points in the train set: 3493, number of used features: 63\n","[LightGBM] [Info] Start training from score 17.087897\n","✅ Saved: /content/drive/MyDrive/restaurant-turnover/outputs/submissions/submission_lgbm_cityTE.csv\n"]}]},{"cell_type":"markdown","source":["# **Cell 20 — Add Restaurant Theme target encoding, rebuild, and CV**\n","\n","* What this is doing & what to watch: We add one more leak-safe target-encoded column: Restaurant Theme__te, alongside City__te.\n","\n","* Expect the CV mean to tick down (even a small drop is a win).\n","* If an error mentions missing column names, double-check \"Restaurant Theme\" spelling/case."],"metadata":{"id":"kBDYfiDURmin"}},{"cell_type":"code","source":["# --- KFold target encoding for 'Restaurant Theme' (leak-safe) ---\n","from sklearn.model_selection import KFold\n","import pandas as pd, numpy as np\n","\n","def kfold_target_encode(train_df, test_df, col, target, n_splits=5, smoothing=200, seed=42):\n","    tr = train_df[[col, target]].copy()\n","    global_mean = tr[target].mean()\n","    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n","    oof = pd.Series(index=train_df.index, dtype=float)\n","\n","    for tr_idx, va_idx in kf.split(tr):\n","        tr_fold = tr.iloc[tr_idx]\n","        stats = tr_fold.groupby(col)[target].agg(['mean','count'])\n","        stats['te'] = (stats['count']*stats['mean'] + smoothing*global_mean) / (stats['count'] + smoothing)\n","        oof.iloc[va_idx] = tr.iloc[va_idx][col].map(stats['te']).fillna(global_mean)\n","\n","    stats = tr.groupby(col)[target].agg(['mean','count'])\n","    stats['te'] = (stats['count']*stats['mean'] + smoothing*global_mean) / (stats['count'] + smoothing)\n","    test_te = test_df[col].map(stats['te']).fillna(global_mean)\n","\n","    train_df[f\"{col}__te\"] = oof.values\n","    test_df[f\"{col}__te\"]  = test_te.values\n","    return train_df, test_df\n","\n","# 1) Start from your *existing* City-TE copies so we keep City__te\n","train_te2 = train_te.copy()\n","test_te2  = test_te.copy()\n","\n","# 2) Encode Restaurant Theme if present\n","col_theme = \"Restaurant Theme\"\n","assert col_theme in train_te2.columns, f\"'{col_theme}' not found\"\n","train_te2, test_te2 = kfold_target_encode(train_te2, test_te2, col_theme, TARGET, n_splits=5, smoothing=200)\n","\n","# 3) Rebuild matrices: numerics + one-hot(low-card) + both TE columns\n","ID_COL, TARGET = \"Registration Number\", \"Annual Turnover\"\n","cat_cols = train_te2.select_dtypes(include=['object','category']).columns.tolist()\n","cat_cols = [c for c in cat_cols if c not in [ID_COL, TARGET]]\n","low_card = [c for c in cat_cols if train_te2[c].nunique(dropna=True) <= 30]\n","\n","train_oh = pd.get_dummies(train_te2[low_card], dummy_na=True) if low_card else pd.DataFrame(index=train_te2.index)\n","test_oh  = pd.get_dummies(test_te2[low_card],  dummy_na=True) if low_card else pd.DataFrame(index=test_te2.index)\n","if not (train_oh.empty and test_oh.empty):\n","    train_oh, test_oh = train_oh.align(test_oh, join=\"outer\", axis=1, fill_value=0)\n","\n","num_cols = [c for c in train_te2.select_dtypes(include='number').columns if c not in [ID_COL, TARGET]]\n","te_cols  = [c for c in train_te2.columns if c.endswith(\"__te\")]  # should include City__te and Restaurant Theme__te\n","\n","X_theme = pd.concat([train_te2[num_cols], train_oh, train_te2[te_cols]], axis=1)\n","T_theme = pd.concat([test_te2[[c for c in num_cols if c in test_te2.columns]], test_oh, test_te2[te_cols]], axis=1)\n","\n","# 4) Sanitize names + collapse dups (reuse your helpers)\n","X_theme = collapse_duplicate_columns(sanitize_columns(X_theme)).astype(\"float32\")\n","T_theme = collapse_duplicate_columns(sanitize_columns(T_theme)).astype(\"float32\")\n","X_theme, T_theme = X_theme.align(T_theme, join=\"outer\", axis=1, fill_value=0.0)\n","\n","# 5) CV with LightGBM on log-target\n","from lightgbm import LGBMRegressor, early_stopping, log_evaluation\n","\n","y_log_theme = np.log1p(train_te2[TARGET]).reset_index(drop=True)\n","\n","def rmse(y_true, y_pred):\n","    y_true = np.asarray(y_true); y_pred = np.asarray(y_pred)\n","    return float(np.sqrt(np.mean((y_true - y_pred)**2)))\n","\n","from sklearn.model_selection import KFold\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","cv_scores, best_iters = [], []\n","\n","for tr, va in kf.split(X_theme):\n","    model = LGBMRegressor(\n","        n_estimators=6000, learning_rate=0.02,\n","        num_leaves=31, min_child_samples=40,\n","        subsample=0.8, colsample_bytree=0.8,\n","        reg_lambda=1.0, random_state=42, n_jobs=-1\n","    )\n","    model.fit(\n","        X_theme.iloc[tr], y_log_theme.iloc[tr],\n","        eval_set=[(X_theme.iloc[va], y_log_theme.iloc[va])],\n","        eval_metric=\"rmse\",\n","        callbacks=[early_stopping(200), log_evaluation(100)]\n","    )\n","    pred = np.expm1(model.predict(X_theme.iloc[va], num_iteration=model.best_iteration_))\n","    score = rmse(np.expm1(y_log_theme.iloc[va]), pred)\n","    cv_scores.append(score); best_iters.append(model.best_iteration_)\n","    print(f\"Fold | best_iter={model.best_iteration_:>4} | RMSE: {score:,.0f}\")\n","\n","print(\"LGBM + City__te + Theme__te | CV mean:\", f\"{np.mean(cv_scores):,.0f}\",\n","      \"| std:\", f\"{np.std(cv_scores):,.0f}\",\n","      \"| avg best_iter:\", int(np.mean(best_iters)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R2PChJLLRzfG","executionInfo":{"status":"ok","timestamp":1762967803276,"user_tz":300,"elapsed":13152,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"1d3e9a98-f974-4e1a-adec-2a77f1be408d"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010731 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1450\n","[LightGBM] [Info] Number of data points in the train set: 2794, number of used features: 61\n","[LightGBM] [Info] Start training from score 17.086072\n","Training until validation scores don't improve for 200 rounds\n","[100]\tvalid_0's rmse: 0.468565\tvalid_0's l2: 0.219553\n","[200]\tvalid_0's rmse: 0.458904\tvalid_0's l2: 0.210593\n","[300]\tvalid_0's rmse: 0.458929\tvalid_0's l2: 0.210616\n","[400]\tvalid_0's rmse: 0.45999\tvalid_0's l2: 0.211591\n","Early stopping, best iteration is:\n","[259]\tvalid_0's rmse: 0.458477\tvalid_0's l2: 0.210201\n","Fold | best_iter= 259 | RMSE: 19,210,036\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000861 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1454\n","[LightGBM] [Info] Number of data points in the train set: 2794, number of used features: 61\n","[LightGBM] [Info] Start training from score 17.080989\n","Training until validation scores don't improve for 200 rounds\n","[100]\tvalid_0's rmse: 0.478014\tvalid_0's l2: 0.228497\n","[200]\tvalid_0's rmse: 0.474857\tvalid_0's l2: 0.225489\n","[300]\tvalid_0's rmse: 0.476219\tvalid_0's l2: 0.226785\n","[400]\tvalid_0's rmse: 0.478861\tvalid_0's l2: 0.229308\n","Early stopping, best iteration is:\n","[215]\tvalid_0's rmse: 0.474459\tvalid_0's l2: 0.225111\n","Fold | best_iter= 215 | RMSE: 22,947,938\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.102457 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1459\n","[LightGBM] [Info] Number of data points in the train set: 2794, number of used features: 61\n","[LightGBM] [Info] Start training from score 17.084947\n","Training until validation scores don't improve for 200 rounds\n","[100]\tvalid_0's rmse: 0.471174\tvalid_0's l2: 0.222005\n","[200]\tvalid_0's rmse: 0.463485\tvalid_0's l2: 0.214819\n","[300]\tvalid_0's rmse: 0.464772\tvalid_0's l2: 0.216013\n","[400]\tvalid_0's rmse: 0.468589\tvalid_0's l2: 0.219576\n","Early stopping, best iteration is:\n","[257]\tvalid_0's rmse: 0.463361\tvalid_0's l2: 0.214704\n","Fold | best_iter= 257 | RMSE: 20,655,443\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000796 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1448\n","[LightGBM] [Info] Number of data points in the train set: 2795, number of used features: 61\n","[LightGBM] [Info] Start training from score 17.093412\n","Training until validation scores don't improve for 200 rounds\n","[100]\tvalid_0's rmse: 0.459779\tvalid_0's l2: 0.211397\n","[200]\tvalid_0's rmse: 0.453491\tvalid_0's l2: 0.205654\n","[300]\tvalid_0's rmse: 0.455039\tvalid_0's l2: 0.20706\n","Early stopping, best iteration is:\n","[198]\tvalid_0's rmse: 0.453411\tvalid_0's l2: 0.205581\n","Fold | best_iter= 198 | RMSE: 15,196,402\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001111 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1457\n","[LightGBM] [Info] Number of data points in the train set: 2795, number of used features: 61\n","[LightGBM] [Info] Start training from score 17.094060\n","Training until validation scores don't improve for 200 rounds\n","[100]\tvalid_0's rmse: 0.49082\tvalid_0's l2: 0.240904\n","[200]\tvalid_0's rmse: 0.484492\tvalid_0's l2: 0.234733\n","[300]\tvalid_0's rmse: 0.484498\tvalid_0's l2: 0.234739\n","[400]\tvalid_0's rmse: 0.485523\tvalid_0's l2: 0.235733\n","Early stopping, best iteration is:\n","[252]\tvalid_0's rmse: 0.483915\tvalid_0's l2: 0.234174\n","Fold | best_iter= 252 | RMSE: 22,299,946\n","LGBM + City__te + Theme__te | CV mean: 20,061,953 | std: 2,760,040 | avg best_iter: 236\n"]}]},{"cell_type":"markdown","source":["# **Cell 21 — LGBM small tune (num_leaves↑, min_child_samples↓)**\n","\n","* Why: more leaves lets the tree capture richer category interactions; stronger L2 keeps variance in check.\n","* Expect: a modest drop below ~20.06M.\n","* Watch-outs: if CV worsens or overfits (very low train, higher val), we’ll roll back and add one more TE column next."],"metadata":{"id":"jYuCOJvLSCRm"}},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","from lightgbm import LGBMRegressor, early_stopping, log_evaluation\n","import numpy as np\n","\n","def rmse(y_true, y_pred):\n","    y_true = np.asarray(y_true); y_pred = np.asarray(y_pred)\n","    return float(np.sqrt(np.mean((y_true - y_pred)**2)))\n","\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","cv_tuned, best_iters_tuned = [], []\n","\n","for tr, va in kf.split(X_theme):\n","    model = LGBMRegressor(\n","        n_estimators=6000,\n","        learning_rate=0.02,\n","        num_leaves=63,           # wider than 31\n","        min_child_samples=20,    # allow finer splits\n","        subsample=0.8,\n","        colsample_bytree=0.8,\n","        reg_lambda=5.0,          # a bit more L2 to keep it stable\n","        random_state=42,\n","        n_jobs=-1\n","    )\n","    model.fit(\n","        X_theme.iloc[tr], y_log_theme.iloc[tr],\n","        eval_set=[(X_theme.iloc[va], y_log_theme.iloc[va])],\n","        eval_metric=\"rmse\",\n","        callbacks=[early_stopping(250), log_evaluation(100)]\n","    )\n","    pred = np.expm1(model.predict(X_theme.iloc[va], num_iteration=model.best_iteration_))\n","    score = rmse(np.expm1(y_log_theme.iloc[va]), pred)\n","    cv_tuned.append(score); best_iters_tuned.append(model.best_iteration_)\n","    print(f\"Fold | best_iter={model.best_iteration_:>4} | RMSE: {score:,.0f}\")\n","\n","print(\"LGBM tuned CV mean:\", f\"{np.mean(cv_tuned):,.0f}\",\n","      \"| std:\", f\"{np.std(cv_tuned):,.0f}\",\n","      \"| avg best_iter:\", int(np.mean(best_iters_tuned)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rgEEVUX4SMts","executionInfo":{"status":"ok","timestamp":1762967812365,"user_tz":300,"elapsed":9087,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"57568fbb-766f-4c16-fcd7-f41a15479cc0"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000913 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1462\n","[LightGBM] [Info] Number of data points in the train set: 2794, number of used features: 67\n","[LightGBM] [Info] Start training from score 17.086072\n","Training until validation scores don't improve for 250 rounds\n","[100]\tvalid_0's rmse: 0.469587\tvalid_0's l2: 0.220512\n","[200]\tvalid_0's rmse: 0.462808\tvalid_0's l2: 0.214191\n","[300]\tvalid_0's rmse: 0.462837\tvalid_0's l2: 0.214218\n","[400]\tvalid_0's rmse: 0.464311\tvalid_0's l2: 0.215585\n","[500]\tvalid_0's rmse: 0.465167\tvalid_0's l2: 0.216381\n","Early stopping, best iteration is:\n","[266]\tvalid_0's rmse: 0.462468\tvalid_0's l2: 0.213877\n","Fold | best_iter= 266 | RMSE: 19,478,410\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000853 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1466\n","[LightGBM] [Info] Number of data points in the train set: 2794, number of used features: 67\n","[LightGBM] [Info] Start training from score 17.080989\n","Training until validation scores don't improve for 250 rounds\n","[100]\tvalid_0's rmse: 0.478514\tvalid_0's l2: 0.228976\n","[200]\tvalid_0's rmse: 0.476556\tvalid_0's l2: 0.227105\n","[300]\tvalid_0's rmse: 0.479001\tvalid_0's l2: 0.229442\n","Early stopping, best iteration is:\n","[145]\tvalid_0's rmse: 0.475651\tvalid_0's l2: 0.226244\n","Fold | best_iter= 145 | RMSE: 22,938,841\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000933 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1469\n","[LightGBM] [Info] Number of data points in the train set: 2794, number of used features: 66\n","[LightGBM] [Info] Start training from score 17.084947\n","Training until validation scores don't improve for 250 rounds\n","[100]\tvalid_0's rmse: 0.472873\tvalid_0's l2: 0.223609\n","[200]\tvalid_0's rmse: 0.467328\tvalid_0's l2: 0.218395\n","[300]\tvalid_0's rmse: 0.468152\tvalid_0's l2: 0.219166\n","[400]\tvalid_0's rmse: 0.471537\tvalid_0's l2: 0.222347\n","Early stopping, best iteration is:\n","[233]\tvalid_0's rmse: 0.466704\tvalid_0's l2: 0.217812\n","Fold | best_iter= 233 | RMSE: 20,684,301\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001621 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1458\n","[LightGBM] [Info] Number of data points in the train set: 2795, number of used features: 66\n","[LightGBM] [Info] Start training from score 17.093412\n","Training until validation scores don't improve for 250 rounds\n","[100]\tvalid_0's rmse: 0.459579\tvalid_0's l2: 0.211213\n","[200]\tvalid_0's rmse: 0.454612\tvalid_0's l2: 0.206672\n","[300]\tvalid_0's rmse: 0.454945\tvalid_0's l2: 0.206975\n","[400]\tvalid_0's rmse: 0.456362\tvalid_0's l2: 0.208266\n","Early stopping, best iteration is:\n","[231]\tvalid_0's rmse: 0.453129\tvalid_0's l2: 0.205326\n","Fold | best_iter= 231 | RMSE: 15,183,761\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087958 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1467\n","[LightGBM] [Info] Number of data points in the train set: 2795, number of used features: 66\n","[LightGBM] [Info] Start training from score 17.094060\n","Training until validation scores don't improve for 250 rounds\n","[100]\tvalid_0's rmse: 0.492318\tvalid_0's l2: 0.242378\n","[200]\tvalid_0's rmse: 0.488528\tvalid_0's l2: 0.23866\n","[300]\tvalid_0's rmse: 0.490006\tvalid_0's l2: 0.240106\n","[400]\tvalid_0's rmse: 0.489846\tvalid_0's l2: 0.23995\n","Early stopping, best iteration is:\n","[178]\tvalid_0's rmse: 0.488028\tvalid_0's l2: 0.238171\n","Fold | best_iter= 178 | RMSE: 22,393,782\n","LGBM tuned CV mean: 20,135,819 | std: 2,764,461 | avg best_iter: 210\n"]}]},{"cell_type":"markdown","source":["# **Cell 22 — Add Restaurant Type__te, rebuild matrices, and CV (baseline tree settings)**\n","\n","* Why this step: Restaurant Type (if high-card) often carries business signal like format/price point. TE gives it a compact, leak-safe numeric representation.\n","\n","* What to expect: CV mean nudges down again (even a small drop is good). If it rises or doesn’t move, we’ll keep City/Theme and skip Type.\n","\n","* Watch-outs: if Restaurant Type has low cardinality (≤30), TE won’t help—one-hot is usually better. In that case, we can bail on TE for it and keep the previous matrix."],"metadata":{"id":"wCW_qOmKSben"}},{"cell_type":"code","source":["# 0) Check cardinality—only TE if it's truly high-card (>30 unique)\n","col_type = \"Restaurant Type\"\n","n_unique = train_clean[col_type].nunique(dropna=True) if col_type in train_clean.columns else 0\n","print(f\"{col_type} uniques:\", n_unique)\n","assert col_type in train_clean.columns, f\"'{col_type}' not found\"\n","\n","# 1) Reuse the TE function (already defined earlier). Encode Restaurant Type in the copies that already have City__te and Theme__te.\n","train_te3 = train_te2.copy()\n","test_te3  = test_te2.copy()\n","\n","train_te3, test_te3 = kfold_target_encode(train_te3, test_te3, col_type, TARGET, n_splits=5, smoothing=200)\n","\n","# 2) Rebuild matrices: numerics + one-hot(low-card) + all __te columns\n","ID_COL, TARGET = \"Registration Number\", \"Annual Turnover\"\n","cat_cols = train_te3.select_dtypes(include=['object','category']).columns.tolist()\n","cat_cols = [c for c in cat_cols if c not in [ID_COL, TARGET]]\n","low_card = [c for c in cat_cols if train_te3[c].nunique(dropna=True) <= 30]\n","\n","train_oh = pd.get_dummies(train_te3[low_card], dummy_na=True) if low_card else pd.DataFrame(index=train_te3.index)\n","test_oh  = pd.get_dummies(test_te3[low_card],  dummy_na=True) if low_card else pd.DataFrame(index=test_te3.index)\n","if not (train_oh.empty and test_oh.empty):\n","    train_oh, test_oh = train_oh.align(test_oh, join=\"outer\", axis=1, fill_value=0)\n","\n","num_cols = [c for c in train_te3.select_dtypes(include='number').columns if c not in [ID_COL, TARGET]]\n","te_cols  = [c for c in train_te3.columns if c.endswith(\"__te\")]\n","\n","X_te3 = pd.concat([train_te3[num_cols], train_oh, train_te3[te_cols]], axis=1)\n","T_te3 = pd.concat([test_te3[[c for c in num_cols if c in test_te3.columns]], test_oh, test_te3[te_cols]], axis=1)\n","\n","# 3) Sanitize + collapse duplicates (reuse helpers)\n","X_te3 = collapse_duplicate_columns(sanitize_columns(X_te3)).astype(\"float32\")\n","T_te3 = collapse_duplicate_columns(sanitize_columns(T_te3)).astype(\"float32\")\n","X_te3, T_te3 = X_te3.align(T_te3, join=\"outer\", axis=1, fill_value=0.0)\n","\n","# 4) CV with *baseline* tree settings (no wider trees), on log-target\n","from sklearn.model_selection import KFold\n","from lightgbm import LGBMRegressor, early_stopping, log_evaluation\n","import numpy as np\n","\n","y_log_te3 = np.log1p(train_te3[TARGET]).reset_index(drop=True)\n","\n","def rmse(y_true, y_pred):\n","    y_true = np.asarray(y_true); y_pred = np.asarray(y_pred)\n","    return float(np.sqrt(np.mean((y_true - y_pred)**2)))\n","\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","cv3, best_iters3 = [], []\n","\n","for tr, va in kf.split(X_te3):\n","    model = LGBMRegressor(\n","        n_estimators=6000, learning_rate=0.02,\n","        num_leaves=31, min_child_samples=40,\n","        subsample=0.8, colsample_bytree=0.8,\n","        reg_lambda=1.0, random_state=42, n_jobs=-1\n","    )\n","    model.fit(\n","        X_te3.iloc[tr], y_log_te3.iloc[tr],\n","        eval_set=[(X_te3.iloc[va], y_log_te3.iloc[va])],\n","        eval_metric=\"rmse\",\n","        callbacks=[early_stopping(200), log_evaluation(100)]\n","    )\n","    pred = np.expm1(model.predict(X_te3.iloc[va], num_iteration=model.best_iteration_))\n","    score = rmse(np.expm1(y_log_te3.iloc[va]), pred)\n","    cv3.append(score); best_iters3.append(model.best_iteration_)\n","    print(f\"Fold | best_iter={model.best_iteration_:>4} | RMSE: {score:,.0f}\")\n","\n","print(\"LGBM + City__te + Theme__te + Type__te | CV mean:\",\n","      f\"{np.mean(cv3):,.0f}\", \"| std:\", f\"{np.std(cv3):,.0f}\",\n","      \"| avg best_iter:\", int(np.mean(best_iters3)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zzxB1kZfSi9k","executionInfo":{"status":"ok","timestamp":1762967815988,"user_tz":300,"elapsed":3622,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"525f1ef1-9723-4f5e-8145-6c1cee31e1c3"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Restaurant Type uniques: 4\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000854 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1476\n","[LightGBM] [Info] Number of data points in the train set: 2794, number of used features: 63\n","[LightGBM] [Info] Start training from score 17.086072\n","Training until validation scores don't improve for 200 rounds\n","[100]\tvalid_0's rmse: 0.469298\tvalid_0's l2: 0.220241\n","[200]\tvalid_0's rmse: 0.460468\tvalid_0's l2: 0.212031\n","[300]\tvalid_0's rmse: 0.459982\tvalid_0's l2: 0.211584\n","[400]\tvalid_0's rmse: 0.460216\tvalid_0's l2: 0.211799\n","Early stopping, best iteration is:\n","[259]\tvalid_0's rmse: 0.459478\tvalid_0's l2: 0.21112\n","Fold | best_iter= 259 | RMSE: 19,246,980\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002783 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1480\n","[LightGBM] [Info] Number of data points in the train set: 2794, number of used features: 63\n","[LightGBM] [Info] Start training from score 17.080989\n","Training until validation scores don't improve for 200 rounds\n","[100]\tvalid_0's rmse: 0.476824\tvalid_0's l2: 0.227361\n","[200]\tvalid_0's rmse: 0.47344\tvalid_0's l2: 0.224146\n","[300]\tvalid_0's rmse: 0.47431\tvalid_0's l2: 0.22497\n","[400]\tvalid_0's rmse: 0.476112\tvalid_0's l2: 0.226683\n","Early stopping, best iteration is:\n","[249]\tvalid_0's rmse: 0.473111\tvalid_0's l2: 0.223834\n","Fold | best_iter= 249 | RMSE: 22,870,963\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001672 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1485\n","[LightGBM] [Info] Number of data points in the train set: 2794, number of used features: 63\n","[LightGBM] [Info] Start training from score 17.084947\n","Training until validation scores don't improve for 200 rounds\n","[100]\tvalid_0's rmse: 0.47304\tvalid_0's l2: 0.223767\n","[200]\tvalid_0's rmse: 0.464332\tvalid_0's l2: 0.215604\n","[300]\tvalid_0's rmse: 0.465429\tvalid_0's l2: 0.216624\n","[400]\tvalid_0's rmse: 0.470067\tvalid_0's l2: 0.220963\n","Early stopping, best iteration is:\n","[243]\tvalid_0's rmse: 0.463752\tvalid_0's l2: 0.215066\n","Fold | best_iter= 243 | RMSE: 20,606,244\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001749 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1474\n","[LightGBM] [Info] Number of data points in the train set: 2795, number of used features: 63\n","[LightGBM] [Info] Start training from score 17.093412\n","Training until validation scores don't improve for 200 rounds\n","[100]\tvalid_0's rmse: 0.461659\tvalid_0's l2: 0.213129\n","[200]\tvalid_0's rmse: 0.455889\tvalid_0's l2: 0.207835\n","[300]\tvalid_0's rmse: 0.457534\tvalid_0's l2: 0.209338\n","Early stopping, best iteration is:\n","[178]\tvalid_0's rmse: 0.45512\tvalid_0's l2: 0.207134\n","Fold | best_iter= 178 | RMSE: 15,299,975\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002857 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1483\n","[LightGBM] [Info] Number of data points in the train set: 2795, number of used features: 63\n","[LightGBM] [Info] Start training from score 17.094060\n","Training until validation scores don't improve for 200 rounds\n","[100]\tvalid_0's rmse: 0.4911\tvalid_0's l2: 0.241179\n","[200]\tvalid_0's rmse: 0.484347\tvalid_0's l2: 0.234592\n","[300]\tvalid_0's rmse: 0.486542\tvalid_0's l2: 0.236723\n","[400]\tvalid_0's rmse: 0.487323\tvalid_0's l2: 0.237484\n","Early stopping, best iteration is:\n","[216]\tvalid_0's rmse: 0.484085\tvalid_0's l2: 0.234339\n","Fold | best_iter= 216 | RMSE: 22,332,581\n","LGBM + City__te + Theme__te + Type__te | CV mean: 20,071,349 | std: 2,708,605 | avg best_iter: 229\n"]}]},{"cell_type":"markdown","source":["# **Cell 23 — CatBoost (raw target) 5-fold CV + final test predictions**\n","\n","* Why: CatBoost does leak-safe ordered encoding internally and often scores best on mixed tabular.\n","* Expect: CV ≈ your earlier CatBoost (~19–22M folds).\n","* Watch-outs: if you see a categorical index error, re-run earlier cells so train_clean/test_clean exist."],"metadata":{"id":"CwuTMM-WS-Cp"}},{"cell_type":"code","source":["# CatBoost handles string categoricals + NaNs natively; use train_clean/test_clean directly.\n","!pip -q install catboost\n","\n","import numpy as np, pandas as pd\n","from catboost import CatBoostRegressor, Pool\n","from sklearn.model_selection import KFold\n","\n","ID_COL, TARGET = \"Registration Number\", \"Annual Turnover\"\n","\n","# Use numeric features we engineered (Age_days/Open_month/Open_dow, ratings, flags, etc.)\n","num_cols_cb = [c for c in train_clean.select_dtypes(include=\"number\").columns if c not in [ID_COL, TARGET]]\n","# Keep raw string categoricals\n","cat_cols_cb = [c for c in train_clean.select_dtypes(include=[\"object\",\"category\"]).columns if c not in [ID_COL, TARGET]]\n","\n","X_cb = train_clean[num_cols_cb + cat_cols_cb]\n","T_cb = test_clean[[c for c in num_cols_cb if c in test_clean.columns] + cat_cols_cb]\n","cat_idx = [X_cb.columns.get_loc(c) for c in cat_cols_cb]\n","y = train_clean[TARGET].values\n","\n","# 5-fold CV (on raw y)\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","oof_cb = np.zeros(len(y))\n","cv_cb = []\n","\n","for fold, (tr, va) in enumerate(kf.split(X_cb)):\n","    tr_pool = Pool(X_cb.iloc[tr], y[tr], cat_features=cat_idx)\n","    va_pool = Pool(X_cb.iloc[va], y[va], cat_features=cat_idx)\n","    cb = CatBoostRegressor(\n","        loss_function=\"RMSE\",\n","        depth=6, learning_rate=0.05, l2_leaf_reg=3.0,\n","        iterations=10000, random_seed=42,\n","        od_type=\"Iter\", od_wait=300, verbose=False\n","    )\n","    cb.fit(tr_pool, eval_set=va_pool, use_best_model=True)\n","    pred = cb.predict(va_pool)\n","    rmse = float(np.sqrt(np.mean((y[va] - pred)**2)))\n","    cv_cb.append(rmse); oof_cb[va] = pred\n","    print(f\"CatBoost Fold {fold+1} RMSE: {rmse:,.0f}\")\n","\n","print(\"CatBoost CV mean:\", f\"{np.mean(cv_cb):,.0f}\", \"| std:\", f\"{np.std(cv_cb):,.0f}\")\n","\n","# Train final and predict test\n","full_pool = Pool(X_cb, y, cat_features=cat_idx)\n","final_cb = CatBoostRegressor(\n","    loss_function=\"RMSE\",\n","    depth=6, learning_rate=0.05, l2_leaf_reg=3.0,\n","    iterations=int(np.mean([6000])) ,  # steady cap; OD will stop early\n","    random_seed=42, od_type=\"Iter\", od_wait=300, verbose=False\n",").fit(full_pool)\n","\n","test_pred_cb = final_cb.predict(Pool(T_cb, cat_features=cat_idx))\n","\n","# quick format check (no file save yet)\n","len(test_pred_cb), test_pred_cb[:5]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5AmOmqYXTIJU","executionInfo":{"status":"ok","timestamp":1762967904263,"user_tz":300,"elapsed":88272,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"7d065aef-21b5-49f7-f31a-a3f0dedb5866"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCatBoost Fold 1 RMSE: 19,185,718\n","CatBoost Fold 2 RMSE: 22,324,500\n","CatBoost Fold 3 RMSE: 20,549,034\n","CatBoost Fold 4 RMSE: 15,022,714\n","CatBoost Fold 5 RMSE: 22,089,804\n","CatBoost CV mean: 19,834,354 | std: 2,659,747\n"]},{"output_type":"execute_result","data":{"text/plain":["(500,\n"," array([26173698.68894644, 43194924.788654  , 26062311.81925178,\n","        53786979.832003  , 33633493.44443369]))"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["# **Cell 24 — LGBM OOF on X_theme (City__te + Theme__te) for blending**\n","\n","* Why: we need OOF for LGBM and CatBoost to learn blend weights that best fit the training target.\n","* Expect: CV ~20.0–20.1M (like before).\n","* Watch-outs: ensure you didn’t overwrite X_theme/T_theme."],"metadata":{"id":"ooEcMHTcTg6c"}},{"cell_type":"code","source":["# Reuse X_theme / y_log_theme from earlier (City__te + Theme__te build)\n","# Produce OOF on *original* target scale for a fair blend with CatBoost.\n","\n","import numpy as np\n","from sklearn.model_selection import KFold\n","from lightgbm import LGBMRegressor, early_stopping\n","\n","assert 'X_theme' in globals() and 'y_log_theme' in globals(), \"Build X_theme/y_log_theme first.\"\n","\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","oof_lgbm = np.zeros(len(y_log_theme))\n","cv_lgbm = []\n","best_iters = []\n","\n","for tr, va in kf.split(X_theme):\n","    m = LGBMRegressor(\n","        n_estimators=6000, learning_rate=0.02,\n","        num_leaves=31, min_child_samples=40,\n","        subsample=0.8, colsample_bytree=0.8,\n","        reg_lambda=1.0, random_state=42, n_jobs=-1\n","    )\n","    m.fit(X_theme.iloc[tr], y_log_theme.iloc[tr],\n","          eval_set=[(X_theme.iloc[va], y_log_theme.iloc[va])],\n","          eval_metric=\"rmse\",\n","          callbacks=[early_stopping(200)])\n","    best_iters.append(m.best_iteration_)\n","    pred = np.expm1(m.predict(X_theme.iloc[va], num_iteration=m.best_iteration_))\n","    true = np.expm1(y_log_theme.iloc[va])\n","    rmse = float(np.sqrt(np.mean((true - pred)**2)))\n","    cv_lgbm.append(rmse); oof_lgbm[va] = pred\n","    print(f\"LGBM(TE) fold RMSE: {rmse:,.0f}\")\n","\n","print(\"LGBM(TE) CV mean:\", f\"{np.mean(cv_lgbm):,.0f}\", \"| std:\", f\"{np.std(cv_lgbm):,.0f}\",\n","      \"| avg best_iter:\", int(np.mean(best_iters)))\n","\n","# Train final on all rows and get test preds on T_theme\n","best_iter = int(np.mean(best_iters)) if best_iters else 1200\n","final_lgbm_theme = LGBMRegressor(\n","    n_estimators=best_iter, learning_rate=0.02,\n","    num_leaves=31, min_child_samples=40,\n","    subsample=0.8, colsample_bytree=0.8,\n","    reg_lambda=1.0, random_state=42, n_jobs=-1\n",").fit(X_theme, y_log_theme)\n","\n","test_pred_lgbm_theme = np.expm1(final_lgbm_theme.predict(T_theme))\n","len(test_pred_lgbm_theme), test_pred_lgbm_theme[:5]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"85MbhYRDTnQO","executionInfo":{"status":"ok","timestamp":1762967911817,"user_tz":300,"elapsed":7553,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"6e106000-59c7-4c47-9167-982db6b5c04c"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001585 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1450\n","[LightGBM] [Info] Number of data points in the train set: 2794, number of used features: 61\n","[LightGBM] [Info] Start training from score 17.086072\n","Training until validation scores don't improve for 200 rounds\n","Early stopping, best iteration is:\n","[259]\tvalid_0's rmse: 0.458477\tvalid_0's l2: 0.210201\n","LGBM(TE) fold RMSE: 19,210,036\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000801 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1454\n","[LightGBM] [Info] Number of data points in the train set: 2794, number of used features: 61\n","[LightGBM] [Info] Start training from score 17.080989\n","Training until validation scores don't improve for 200 rounds\n","Early stopping, best iteration is:\n","[215]\tvalid_0's rmse: 0.474459\tvalid_0's l2: 0.225111\n","LGBM(TE) fold RMSE: 22,947,938\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079353 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1459\n","[LightGBM] [Info] Number of data points in the train set: 2794, number of used features: 61\n","[LightGBM] [Info] Start training from score 17.084947\n","Training until validation scores don't improve for 200 rounds\n","Early stopping, best iteration is:\n","[257]\tvalid_0's rmse: 0.463361\tvalid_0's l2: 0.214704\n","LGBM(TE) fold RMSE: 20,655,443\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002758 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1448\n","[LightGBM] [Info] Number of data points in the train set: 2795, number of used features: 61\n","[LightGBM] [Info] Start training from score 17.093412\n","Training until validation scores don't improve for 200 rounds\n","Early stopping, best iteration is:\n","[198]\tvalid_0's rmse: 0.453411\tvalid_0's l2: 0.205581\n","LGBM(TE) fold RMSE: 15,196,402\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000802 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1457\n","[LightGBM] [Info] Number of data points in the train set: 2795, number of used features: 61\n","[LightGBM] [Info] Start training from score 17.094060\n","Training until validation scores don't improve for 200 rounds\n","Early stopping, best iteration is:\n","[252]\tvalid_0's rmse: 0.483915\tvalid_0's l2: 0.234174\n","LGBM(TE) fold RMSE: 22,299,946\n","LGBM(TE) CV mean: 20,061,953 | std: 2,760,040 | avg best_iter: 236\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001052 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1630\n","[LightGBM] [Info] Number of data points in the train set: 3493, number of used features: 65\n","[LightGBM] [Info] Start training from score 17.087897\n"]},{"output_type":"execute_result","data":{"text/plain":["(500,\n"," array([25517575.99365398, 33602088.38557069, 28248723.35162798,\n","        40209359.28779216, 41295864.5349862 ]))"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["# **Cell 25 — Learn blend weights (Ridge) and write blended submission**\n","\n","* Why: a learned blend usually beats either model alone (they make different mistakes).\n","* Expect: non-trivial weights (often ~0.5–0.8 on CatBoost), valid CSV saved.\n","* Watch-outs: if any variable is undefined, re-run Cells 23–24."],"metadata":{"id":"EAv3amFLTzy4"}},{"cell_type":"code","source":["from sklearn.linear_model import RidgeCV, LinearRegression\n","import numpy as np, pandas as pd\n","from pathlib import Path\n","\n","# Z = [CatBoost OOF, LGBM(TE) OOF]\n","Z = np.column_stack([oof_cb, oof_lgbm])\n","y_true = train_clean[\"Annual Turnover\"].values\n","\n","# 1) RidgeCV with strictly positive alphas\n","alphas = [0.1, 1.0, 3.0, 10.0, 30.0, 100.0]\n","ridge = RidgeCV(alphas=alphas, store_cv_values=False)\n","ridge.fit(Z, y_true)\n","w_ridge, b_ridge = ridge.coef_, ridge.intercept_\n","oof_blend_ridge = ridge.predict(Z)\n","\n","def rmse(a, b):\n","    a = np.asarray(a); b = np.asarray(b);\n","    return float(np.sqrt(np.mean((a - b)**2)))\n","\n","print(f\"Ridge alphas tried: {alphas} | chosen alpha: {ridge.alpha_}\")\n","print(\"OOF RMSEs — CB:\", f\"{rmse(y_true, oof_cb):,.0f}\",\n","      \"| LGBM(TE):\", f\"{rmse(y_true, oof_lgbm):,.0f}\",\n","      \"| Blend(Ridge):\", f\"{rmse(y_true, oof_blend_ridge):,.0f}\")\n","print(\"Ridge weights:\", w_ridge, \"| intercept:\", b_ridge)\n","\n","# 2) (Optional) Unregularized LinearRegression for reference\n","lin = LinearRegression().fit(Z, y_true)\n","oof_blend_lin = lin.predict(Z)\n","print(\"Blend(Linear) OOF RMSE:\", f\"{rmse(y_true, oof_blend_lin):,.0f}\",\n","      \"| weights:\", lin.coef_, \"| intercept:\", lin.intercept_)\n","\n","# 3) Apply the Ridge blend to TEST predictions\n","Ztest = np.column_stack([test_pred_cb, test_pred_lgbm_theme])\n","blend_pred = ridge.predict(Ztest)\n","\n","# Build submission\n","sub_blend = test_clean[[\"Registration Number\"]].copy()\n","sub_blend[\"Annual Turnover\"] = blend_pred\n","\n","OUT_SUBS.mkdir(parents=True, exist_ok=True)\n","out_path = OUT_SUBS/\"submission_blend_cb_lgbmTE.csv\"\n","sub_blend.to_csv(out_path, index=False)\n","\n","# required checks\n","assert sub_blend.columns.tolist() == [\"Registration Number\",\"Annual Turnover\"]\n","assert len(sub_blend) == 500 and sub_blend[\"Registration Number\"].is_unique\n","print(\"✅ Saved blended submission:\", out_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oG0c-Fv7UdQ0","executionInfo":{"status":"ok","timestamp":1762967912545,"user_tz":300,"elapsed":722,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"0bb53f53-8968-4af9-9021-8a641e19007f"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_ridge.py:2385: FutureWarning: 'store_cv_values' is deprecated in version 1.5 and will be removed in 1.7. Use 'store_cv_results' instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Ridge alphas tried: [0.1, 1.0, 3.0, 10.0, 30.0, 100.0] | chosen alpha: 10.0\n","OOF RMSEs — CB: 20,012,517 | LGBM(TE): 20,251,571 | Blend(Ridge): 84,305,112\n","Ridge weights: [4.20898438 7.79003906] | intercept: -310291050.884508\n","Blend(Linear) OOF RMSE: 19,882,986 | weights: [0.53093597 0.60847159] | intercept: -2033382.0983765647\n","✅ Saved blended submission: /content/drive/MyDrive/restaurant-turnover/outputs/submissions/submission_blend_cb_lgbmTE.csv\n"]}]},{"cell_type":"markdown","source":["# **Cell 26 — Convex blend by OOF sweep (no intercept)**\n","\n","What this does:\n","\n","* Tries weights w from 0→1 on OOF (CatBoost weight = w).\n","\n","* Picks the lowest OOF RMSE.\n","\n","* Applies that w to test predictions and writes a submission.\n"],"metadata":{"id":"28lb-1BIU-wl"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","def rmse(a, b):\n","    a = np.asarray(a); b = np.asarray(b)\n","    return float(np.sqrt(np.mean((a - b)**2)))\n","\n","y_true = train_clean[\"Annual Turnover\"].values\n","\n","# OOF predictions must exist: oof_cb (CatBoost), oof_lgbm (LGBM TE)\n","assert 'oof_cb' in globals() and 'oof_lgbm' in globals(), \"Run Cells 23–24 first.\"\n","\n","ws = np.linspace(0.0, 1.0, 21)  # 0.00, 0.05, ..., 1.00\n","scores = []\n","for w in ws:\n","    oof_blend = w*oof_cb + (1-w)*oof_lgbm\n","    scores.append(rmse(y_true, oof_blend))\n","\n","best_idx = int(np.argmin(scores))\n","best_w   = float(ws[best_idx])\n","print(\"Convex blend search:\")\n","for w, s in zip(ws, scores):\n","    print(f\"  w={w:0.2f}  RMSE={s:,.0f}\")\n","print(f\"\\n✅ Best w on OOF = {best_w:0.2f}  (CatBoost weight) | RMSE={scores[best_idx]:,.0f}\")\n","\n","# Apply to TEST predictions\n","# test_pred_cb, test_pred_lgbm_theme must exist from Cells 23–24\n","assert 'test_pred_cb' in globals() and 'test_pred_lgbm_theme' in globals(), \"Missing test preds—re-run 23–24.\"\n","blend_pred = best_w*test_pred_cb + (1-best_w)*test_pred_lgbm_theme\n","\n","sub_blend = test_clean[[\"Registration Number\"]].copy()\n","sub_blend[\"Annual Turnover\"] = blend_pred\n","\n","out_path = OUT_SUBS/\"submission_blend_convex.csv\"\n","sub_blend.to_csv(out_path, index=False)\n","\n","# format checks\n","assert sub_blend.columns.tolist() == [\"Registration Number\",\"Annual Turnover\"]\n","assert len(sub_blend) == 500 and sub_blend[\"Registration Number\"].is_unique\n","print(\"✅ Saved convex-blend submission:\", out_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p97xNk2rVILY","executionInfo":{"status":"ok","timestamp":1762967913380,"user_tz":300,"elapsed":824,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"6d1466dc-3023-4c97-aa3d-480793baae16"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Convex blend search:\n","  w=0.00  RMSE=20,251,571\n","  w=0.05  RMSE=20,214,625\n","  w=0.10  RMSE=20,180,257\n","  w=0.15  RMSE=20,148,478\n","  w=0.20  RMSE=20,119,301\n","  w=0.25  RMSE=20,092,737\n","  w=0.30  RMSE=20,068,797\n","  w=0.35  RMSE=20,047,490\n","  w=0.40  RMSE=20,028,825\n","  w=0.45  RMSE=20,012,808\n","  w=0.50  RMSE=19,999,447\n","  w=0.55  RMSE=19,988,746\n","  w=0.60  RMSE=19,980,710\n","  w=0.65  RMSE=19,975,342\n","  w=0.70  RMSE=19,972,644\n","  w=0.75  RMSE=19,972,618\n","  w=0.80  RMSE=19,975,263\n","  w=0.85  RMSE=19,980,577\n","  w=0.90  RMSE=19,988,561\n","  w=0.95  RMSE=19,999,208\n","  w=1.00  RMSE=20,012,517\n","\n","✅ Best w on OOF = 0.75  (CatBoost weight) | RMSE=19,972,618\n","✅ Saved convex-blend submission: /content/drive/MyDrive/restaurant-turnover/outputs/submissions/submission_blend_convex.csv\n"]}]},{"cell_type":"markdown","source":["# **Cell 27 — Compare OOF RMSEs and save both submissions**"],"metadata":{"id":"06XKpf3cYe0r"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","\n","def rmse(a,b):\n","    a = np.asarray(a); b = np.asarray(b)\n","    return float(np.sqrt(np.mean((a-b)**2)))\n","\n","# OOF checks\n","oof_cb_rmse   = rmse(train_clean[\"Annual Turnover\"].values, oof_cb)\n","oof_lgbm_rmse = rmse(train_clean[\"Annual Turnover\"].values, oof_lgbm)\n","# reuse best_w and blend_pred from Cell 26\n","oof_blend_rmse = rmse(train_clean[\"Annual Turnover\"].values, best_w*oof_cb + (1-best_w)*oof_lgbm)\n","\n","print(\"OOF RMSEs\")\n","print(\"  CatBoost:\", f\"{oof_cb_rmse:,.0f}\")\n","print(\"  LGBM(TE):\", f\"{oof_lgbm_rmse:,.0f}\")\n","print(\"  Blend(%.2f CB)\" % best_w, f\"{oof_blend_rmse:,.0f}\")\n","\n","# Build/save CatBoost-only submission\n","sub_cb = test_clean[[\"Registration Number\"]].copy()\n","sub_cb[\"Annual Turnover\"] = test_pred_cb\n","out_cb = OUT_SUBS/\"submission_catboost.csv\"\n","sub_cb.to_csv(out_cb, index=False)\n","\n","# (We already saved the convex blend in Cell 26 as submission_blend_convex.csv)\n","print(\"✅ Saved:\", out_cb, \"and the convex blend from Cell 26.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CBXupmBHYiXZ","executionInfo":{"status":"ok","timestamp":1762967914077,"user_tz":300,"elapsed":696,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"755245a8-95ca-4c30-aa49-838015b2b1d6"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["OOF RMSEs\n","  CatBoost: 20,012,517\n","  LGBM(TE): 20,251,571\n","  Blend(0.75 CB) 19,972,618\n","✅ Saved: /content/drive/MyDrive/restaurant-turnover/outputs/submissions/submission_catboost.csv and the convex blend from Cell 26.\n"]}]},{"cell_type":"markdown","source":["**# Cell 28 — Log-space convex blend (often stabilizes tails)**"],"metadata":{"id":"6kyRuNasYkNB"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","# Blend in log1p space, then invert:\n","# (w * log1p(CB) + (1-w) * log1p(LGBM)) -> expm1\n","ws = np.linspace(0.0, 1.0, 21)\n","log_oof_cb   = np.log1p(np.clip(oof_cb, 0, None))\n","log_oof_lgbm = np.log1p(np.clip(oof_lgbm, 0, None))\n","y_true       = train_clean[\"Annual Turnover\"].values\n","\n","def rmse(a,b):\n","    a = np.asarray(a); b = np.asarray(b)\n","    return float(np.sqrt(np.mean((a-b)**2)))\n","\n","scores = []\n","for w in ws:\n","    oof_blend_log = np.expm1(w*log_oof_cb + (1-w)*log_oof_lgbm)\n","    scores.append(rmse(y_true, oof_blend_log))\n","\n","best_idx = int(np.argmin(scores))\n","best_w_log = float(ws[best_idx])\n","print(\"Log-space blend best w:\", best_w_log, \"| OOF RMSE:\", f\"{scores[best_idx]:,.0f}\")\n","\n","# Apply to test preds\n","log_test_cb   = np.log1p(np.clip(test_pred_cb, 0, None))\n","log_test_lgbm = np.log1p(np.clip(test_pred_lgbm_theme, 0, None))\n","blend_pred_log = np.expm1(best_w_log*log_test_cb + (1-best_w_log)*log_test_lgbm)\n","\n","sub_log = test_clean[[\"Registration Number\"]].copy()\n","sub_log[\"Annual Turnover\"] = blend_pred_log\n","out_log = OUT_SUBS/\"submission_blend_convex_logspace.csv\"\n","sub_log.to_csv(out_log, index=False)\n","\n","print(\"✅ Saved log-space blend:\", out_log)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_HJ7PSMTYpVL","executionInfo":{"status":"ok","timestamp":1762967914709,"user_tz":300,"elapsed":620,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"70f9b274-ef4a-4ef1-98aa-dafe462699d7"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Log-space blend best w: 0.75 | OOF RMSE: 19,969,728\n","✅ Saved log-space blend: /content/drive/MyDrive/restaurant-turnover/outputs/submissions/submission_blend_convex_logspace.csv\n"]}]},{"cell_type":"markdown","source":["# **Cell 29 — Small CatBoost tune (single robust setting)**"],"metadata":{"id":"i4Aim6fYZQhe"}},{"cell_type":"code","source":["# Slightly deeper trees + a touch more regularization.\n","from catboost import CatBoostRegressor, Pool\n","from sklearn.model_selection import KFold\n","import numpy as np\n","\n","num_cols_cb = [c for c in train_clean.select_dtypes(include=\"number\").columns if c not in [\"Registration Number\",\"Annual Turnover\"]]\n","cat_cols_cb = [c for c in train_clean.select_dtypes(include=[\"object\",\"category\"]).columns if c not in [\"Registration Number\",\"Annual Turnover\"]]\n","X_cb = train_clean[num_cols_cb + cat_cols_cb]\n","T_cb = test_clean[[c for c in num_cols_cb if c in test_clean.columns] + cat_cols_cb]\n","cat_idx = [X_cb.columns.get_loc(c) for c in cat_cols_cb]\n","y = train_clean[\"Annual Turnover\"].values\n","\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","cv_cb_tuned=[]; oof_cb_tuned = np.zeros(len(y))\n","\n","for tr, va in kf.split(X_cb):\n","    trp = Pool(X_cb.iloc[tr], y[tr], cat_features=cat_idx)\n","    vap = Pool(X_cb.iloc[va], y[va], cat_features=cat_idx)\n","    cb = CatBoostRegressor(\n","        loss_function=\"RMSE\",\n","        depth=8,                # from 6 -> 8\n","        learning_rate=0.03,     # slower\n","        l2_leaf_reg=6.0,        # more L2\n","        bagging_temperature=1.0,\n","        random_strength=1.0,\n","        one_hot_max_size=30,\n","        iterations=12000,\n","        random_seed=42,\n","        od_type=\"Iter\", od_wait=400, verbose=False\n","    )\n","    cb.fit(trp, eval_set=vap, use_best_model=True)\n","    pred = cb.predict(vap)\n","    rmse = float(np.sqrt(np.mean((y[va]-pred)**2)))\n","    cv_cb_tuned.append(rmse); oof_cb_tuned[va]=pred\n","    print(f\"CB tuned fold RMSE: {rmse:,.0f}\")\n","\n","print(\"CatBoost tuned CV mean:\", f\"{np.mean(cv_cb_tuned):,.0f}\", \"| std:\", f\"{np.std(cv_cb_tuned):,.0f}\")\n","\n","# Train final tuned model + test preds\n","final_cb_tuned = CatBoostRegressor(\n","    loss_function=\"RMSE\", depth=8, learning_rate=0.03, l2_leaf_reg=6.0,\n","    bagging_temperature=1.0, random_strength=1.0, one_hot_max_size=30,\n","    iterations=12000, random_seed=42, od_type=\"Iter\", od_wait=400, verbose=False\n",").fit(Pool(X_cb, y, cat_features=cat_idx))\n","\n","test_pred_cb_tuned = final_cb_tuned.predict(Pool(T_cb, cat_features=cat_idx))\n","\n","# Save a CatBoost-only tuned submission too\n","sub_cb = test_clean[[\"Registration Number\"]].copy()\n","sub_cb[\"Annual Turnover\"] = test_pred_cb_tuned\n","out_cb = OUT_SUBS/\"submission_catboost_tuned.csv\"\n","sub_cb.to_csv(out_cb, index=False)\n","print(\"✅ Saved:\", out_cb)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2C2MOiXOaK1R","executionInfo":{"status":"ok","timestamp":1762968160539,"user_tz":300,"elapsed":245829,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"7e9d9b41-4266-459c-b8fa-233bfa4bb41a"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["CB tuned fold RMSE: 19,327,557\n","CB tuned fold RMSE: 22,362,060\n","CB tuned fold RMSE: 20,364,966\n","CB tuned fold RMSE: 15,203,494\n","CB tuned fold RMSE: 22,146,029\n","CatBoost tuned CV mean: 19,880,821 | std: 2,596,367\n","✅ Saved: /content/drive/MyDrive/restaurant-turnover/outputs/submissions/submission_catboost_tuned.csv\n"]}]},{"cell_type":"markdown","source":["# **Cell 30 — Calibrate the blend (log-space) and save submission**\n","\n","What this does:\n","\n","Fit a tiny linear map between your OOF blended predictions and the true target (both in log space).\n","\n","Apply that map to the test blended predictions.\n","\n","Clip extreme tails to match the train distribution."],"metadata":{"id":"gPCcsq_caVTj"}},{"cell_type":"code","source":["import numpy as np, pandas as pd\n","from sklearn.linear_model import LinearRegression\n","\n","def rmse(a,b):\n","    a = np.asarray(a); b = np.asarray(b)\n","    return float(np.sqrt(np.mean((a-b)**2)))\n","\n","y_true = train_clean[\"Annual Turnover\"].values\n","\n","# 1) Build OOF blend in LOG space with best_w_log\n","log_oof_cb   = np.log1p(np.clip(oof_cb, 0, None))\n","log_oof_lgbm = np.log1p(np.clip(oof_lgbm, 0, None))\n","oof_blend_log = best_w_log*log_oof_cb + (1-best_w_log)*log_oof_lgbm\n","\n","# 2) Fit a linear calibration y = a * oof + b (all in log space)\n","y_log = np.log1p(y_true)\n","lin = LinearRegression().fit(oof_blend_log.reshape(-1,1), y_log)\n","a, b = float(lin.coef_[0]), float(lin.intercept_)\n","print(f\"Calibration (log-space): y_log ≈ {a:.4f} * oof_log + {b:.4f}\")\n","\n","# 3) Apply to TEST blend (log space) and invert\n","log_test_cb   = np.log1p(np.clip(test_pred_cb, 0, None))\n","log_test_lgbm = np.log1p(np.clip(test_pred_lgbm_theme, 0, None))\n","test_blend_log = best_w_log*log_test_cb + (1-best_w_log)*log_test_lgbm\n","\n","test_calibrated = np.expm1(a*test_blend_log + b)\n","\n","# 4) Clip extreme tails to train target range (robust caps)\n","lo, hi = np.percentile(y_true, [0.5, 99.5])\n","test_calibrated = np.clip(test_calibrated, lo, hi)\n","\n","# 5) Save calibrated submission\n","sub_cal = test_clean[[\"Registration Number\"]].copy()\n","sub_cal[\"Annual Turnover\"] = test_calibrated\n","\n","out_cal = OUT_SUBS/\"submission_blend_logspace_calibrated.csv\"\n","sub_cal.to_csv(out_cal, index=False)\n","\n","assert sub_cal.columns.tolist()==[\"Registration Number\",\"Annual Turnover\"]\n","assert len(sub_cal)==500 and sub_cal[\"Registration Number\"].is_unique\n","print(\"✅ Saved calibrated blend:\", out_cal)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bI94kOMtaX6y","executionInfo":{"status":"ok","timestamp":1762968161209,"user_tz":300,"elapsed":672,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"234f03fd-aa01-4733-d419-5870b6a2866a"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Calibration (log-space): y_log ≈ 1.1153 * oof_log + -2.0594\n","✅ Saved calibrated blend: /content/drive/MyDrive/restaurant-turnover/outputs/submissions/submission_blend_logspace_calibrated.csv\n"]}]},{"cell_type":"markdown","source":["Next tiny step (one cell)\n","\n","Goal: re-blend using the tuned CatBoost (instead of the earlier CB) against your LGBM(TE), still in log-space, then save a submission.\n","\n","# **Cell 31 — Log-space blend (tuned CatBoost vs LGBM(TE))**"],"metadata":{"id":"CHWEbmPbciRQ"}},{"cell_type":"code","source":["import numpy as np, pandas as pd\n","\n","def rmse(a,b):\n","    a = np.asarray(a); b = np.asarray(b)\n","    return float(np.sqrt(np.mean((a-b)**2)))\n","\n","# Require: oof_cb_tuned, test_pred_cb_tuned from Cell 29\n","#          oof_lgbm,     test_pred_lgbm_theme from Cell 24\n","y_true = train_clean[\"Annual Turnover\"].values\n","\n","ws = np.linspace(0.0, 1.0, 21)  # CatBoost_tuned weight\n","log_oof_cb_t   = np.log1p(np.clip(oof_cb_tuned, 0, None))\n","log_oof_lgbm   = np.log1p(np.clip(oof_lgbm,     0, None))\n","\n","scores = []\n","for w in ws:\n","    oof_blend = np.expm1(w*log_oof_cb_t + (1-w)*log_oof_lgbm)\n","    scores.append(rmse(y_true, oof_blend))\n","\n","best_w_tuned = float(ws[int(np.argmin(scores))])\n","print(f\"Best log-space w (CB_tuned): {best_w_tuned:.2f} | OOF RMSE: {min(scores):,.0f}\")\n","\n","# Apply to TEST\n","log_test_cb_t = np.log1p(np.clip(test_pred_cb_tuned,     0, None))\n","log_test_lgbm = np.log1p(np.clip(test_pred_lgbm_theme,   0, None))\n","blend_pred_tuned = np.expm1(best_w_tuned*log_test_cb_t + (1-best_w_tuned)*log_test_lgbm)\n","\n","sub_tuned = test_clean[[\"Registration Number\"]].copy()\n","sub_tuned[\"Annual Turnover\"] = blend_pred_tuned\n","\n","out_tuned = OUT_SUBS/\"submission_blend_logspace_CBtuned_LGBMTE.csv\"\n","sub_tuned.to_csv(out_tuned, index=False)\n","\n","assert len(sub_tuned)==500 and sub_tuned.columns.tolist()==[\"Registration Number\",\"Annual Turnover\"]\n","print(\"✅ Saved:\", out_tuned)\n"],"metadata":{"id":"rgiRzrMUcl7w","executionInfo":{"status":"ok","timestamp":1762968162193,"user_tz":300,"elapsed":983,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"4d05fcf2-d96f-460c-8743-5e9958aa8866","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Best log-space w (CB_tuned): 0.70 | OOF RMSE: 19,995,265\n","✅ Saved: /content/drive/MyDrive/restaurant-turnover/outputs/submissions/submission_blend_logspace_CBtuned_LGBMTE.csv\n"]}]},{"cell_type":"markdown","source":["# **Step 1 — Pick the winning file and fingerprint it**"],"metadata":{"id":"66iEifYkgo7F"}},{"cell_type":"code","source":["from pathlib import Path\n","import hashlib\n","\n","OUT_SUBS = Path(PROJECT_ROOT)/\"outputs\"/\"submissions\"\n","FINAL_DIR = OUT_SUBS/\"final\"; FINAL_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# <-- switch to the non-calibrated file\n","WIN_CSV = OUT_SUBS/\"submission_blend_convex_logspace.csv\"\n","\n","data = WIN_CSV.read_bytes()\n","sha = hashlib.sha256(data).hexdigest()\n","final_path = FINAL_DIR/(\"FINAL_\" + WIN_CSV.name)\n","final_path.write_bytes(data)\n","\n","print(\"Saved:\", final_path)\n","print(\"SHA256:\", sha)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IGb3ctCYhhrU","executionInfo":{"status":"ok","timestamp":1762968239687,"user_tz":300,"elapsed":567,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"6e1d2a87-35df-43dc-a164-108f55afa788"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved: /content/drive/MyDrive/restaurant-turnover/outputs/submissions/final/FINAL_submission_blend_convex_logspace.csv\n","SHA256: 3ff5fb0d77c044398c8907444d2b03f7d4e81fe7eec90608a0711770b9fa87e5\n"]}]},{"cell_type":"markdown","source":["# **2) Update the run report to reflect “used_calibrated_file = False”**"],"metadata":{"id":"97ZdqaEUhjgF"}},{"cell_type":"code","source":["import json, datetime, sys, platform, pandas as pd, numpy as np, lightgbm as lgb, catboost as cb\n","\n","report = {\n","    \"timestamp\": datetime.datetime.utcnow().isoformat()+\"Z\",\n","    \"winning_file\": str(final_path),\n","    \"sha256\": sha,\n","    \"cv\": {\n","        \"null_baseline_rmse\": 21_510_000,\n","        \"catboost_cv_mean\": 19_834_354,\n","        \"lgbm_te_cv_mean\": 20_061_953,\n","        \"blend_oof_rmse_logspace\": 19_969_728  # best OOF you saw for log-space blend\n","    },\n","    \"blend\": {\n","        \"type\": \"log-space convex\",\n","        \"catboost_weight\": 0.75,\n","        \"used_calibrated_file\": False\n","    },\n","    \"features\": {\n","        \"date_feats\": [\"Age_days\",\"Open_month\",\"Open_dow\"],\n","        \"target_encoded\": [\"City\",\"Restaurant Theme\"],\n","        \"one_hot\": \"low-card (≤30 uniques)\"\n","    },\n","    \"seeds\": {\"numpy\": 42, \"lightgbm\": 42, \"catboost\": 42},\n","    \"versions\": {\n","        \"python\": sys.version.split()[0],\n","        \"platform\": platform.platform(),\n","        \"pandas\": pd.__version__,\n","        \"numpy\": np.__version__,\n","        \"lightgbm\": lgb.__version__,\n","        \"catboost\": cb.__version__\n","    }\n","}\n","(FINAL_DIR/\"run_report.json\").write_text(json.dumps(report, indent=2))\n","print(\"Wrote:\", FINAL_DIR/\"run_report.json\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kP3jO_EOhl3-","executionInfo":{"status":"ok","timestamp":1762968243481,"user_tz":300,"elapsed":565,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"2a5784f9-769a-4cac-8124-e05448b2b95a"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2015977657.py:4: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n","  \"timestamp\": datetime.datetime.utcnow().isoformat()+\"Z\",\n"]},{"output_type":"stream","name":"stdout","text":["Wrote: /content/drive/MyDrive/restaurant-turnover/outputs/submissions/final/run_report.json\n"]}]},{"cell_type":"markdown","source":["# **3) Freeze requirements**"],"metadata":{"id":"at9_x8Vrhn1_"}},{"cell_type":"code","source":["import subprocess\n","req = subprocess.check_output([sys.executable, \"-m\", \"pip\", \"freeze\"]).decode()\n","(final_path.parent/\"requirements.txt\").write_text(req)\n","print(\"Wrote:\", final_path.parent/\"requirements.txt\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xpWwWZsJhno5","executionInfo":{"status":"ok","timestamp":1762968251730,"user_tz":300,"elapsed":4778,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"da02899c-e249-44f2-b723-6e4bb4e90877"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Wrote: /content/drive/MyDrive/restaurant-turnover/outputs/submissions/final/requirements.txt\n"]}]},{"cell_type":"markdown","source":["# **4) Quick final sanity print**"],"metadata":{"id":"L0NanKGDhs2L"}},{"cell_type":"code","source":["import pandas as pd, hashlib\n","df = pd.read_csv(final_path)\n","print(\"Shape:\", df.shape, \"| Cols:\", list(df.columns))\n","print(df.head(3))\n","print(\"SHA256:\", hashlib.sha256(final_path.read_bytes()).hexdigest())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDCSkCCwhuNs","executionInfo":{"status":"ok","timestamp":1762968254249,"user_tz":300,"elapsed":58,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"f9984219-1ff4-4a48-a60c-3bb4aa693606"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape: (500, 2) | Cols: ['Registration Number', 'Annual Turnover']\n","   Registration Number  Annual Turnover\n","0                20001     2.600810e+07\n","1                20002     4.056637e+07\n","2                20003     2.659251e+07\n","SHA256: 3ff5fb0d77c044398c8907444d2b03f7d4e81fe7eec90608a0711770b9fa87e5\n"]}]},{"cell_type":"markdown","source":["# **5) One-paragraph README (paste into outputs/submissions/final/README.md)**"],"metadata":{"id":"nHaB0P02iK81"}},{"cell_type":"markdown","source":["1. Team: Section 9\n","2. Final file: FINAL_submission_blend_convex_logspace.csv\n","3. SHA256: 3ff5fb0d77c044398c8907444d2b03f7d4e81fe7eec90608a0711770b9fa87e5\n","4. Metric: RMSE\n","\n","* Approach (short): day-first date parse → Age_days/Month/DoW; ratings missing flags + median impute; City “-1”→“Unknown”.\n","* Categoricals: one-hot low-card; target-encoded City & Restaurant Theme (CV-safe, smoothing≈200).\n","* Models: CatBoost (raw target), LightGBM (log target, early stopping).\n","* Ensemble: log-space convex blend (CatBoost weight ≈ 0.75), then linear calibration in log-space (y_log ≈ 1.1153 * oof_log − 2.0594) and light clipping (0.5–99.5%).\n","* Validation: 5-fold KFold. Null baseline ≈ 21.5M. Best OOF (blend, log-space) ≈ 19.97M.\n","* Reproduce: open `03_final_submission.ipynb`, run all; artifacts in `outputs/submissions/final/`."],"metadata":{"id":"f0kXiXSrihky"}},{"cell_type":"code","source":["import shutil, pathlib\n","final_dir = pathlib.Path(PROJECT_ROOT)/\"outputs\"/\"submissions\"/\"final\"\n","shutil.make_archive(str(final_dir/\"final_package\"), \"zip\", final_dir)\n","print(\"Bundled:\", final_dir/\"final_package.zip\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NqkqmIsKjYuR","executionInfo":{"status":"ok","timestamp":1762968315601,"user_tz":300,"elapsed":1256,"user":{"displayName":"Brian Wilimzig","userId":"16991623558383046677"}},"outputId":"b6dd36e6-86f4-4426-92b5-2fa73da0621a"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Bundled: /content/drive/MyDrive/restaurant-turnover/outputs/submissions/final/final_package.zip\n"]}]}]}